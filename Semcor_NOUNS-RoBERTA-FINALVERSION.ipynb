{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loakwltyiSsI"
   },
   "source": [
    "# ROBERTA model for predicting nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fWP6M59Rwdns"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import logging\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.7.10\n",
      "IPython version      : 7.20.0\n",
      "\n",
      "numpy       : 1.19.2\n",
      "pandas      : 1.2.2\n",
      "torch       : 1.8.1+cu111\n",
      "transformers: 4.4.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device\n",
    "\n",
    "if device == 'cuda':\n",
    "    gpu_server = True # in case we run the notebook on Colab, set it to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "w8ZZzwl2wfNA",
    "outputId": "a14f28fa-f620-406a-9ce8-6e8b68ef61b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text|@id</th>\n",
       "      <th>text|sentence|@id</th>\n",
       "      <th>text|sentence|instance</th>\n",
       "      <th>text|sentence|instance|@id</th>\n",
       "      <th>text|sentence|instance|@lemma</th>\n",
       "      <th>text|sentence|instance|@pos</th>\n",
       "      <th>lexelt|sense|@id</th>\n",
       "      <th>lexelt|@item</th>\n",
       "      <th>lexelt|@pos</th>\n",
       "      <th>lexelt|@sence_count_wn</th>\n",
       "      <th>lexelt|@sense_count_corpus</th>\n",
       "      <th>lexelt|@word_example_count</th>\n",
       "      <th>lexelt|sense|@gloss</th>\n",
       "      <th>lexelt|sense|@sense_example_count</th>\n",
       "      <th>lexelt|sense|@sense_freq</th>\n",
       "      <th>lexelt|sense|@synset</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d000</td>\n",
       "      <td>d000.s000</td>\n",
       "      <td>long</td>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>long</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>long%3:00:02::</td>\n",
       "      <td>long#a</td>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>primarily temporal sense; being or indicating ...</td>\n",
       "      <td>102</td>\n",
       "      <td>118</td>\n",
       "      <td>long</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>d000</td>\n",
       "      <td>d000.s000</td>\n",
       "      <td>been</td>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>be%2:42:03::</td>\n",
       "      <td>be#v</td>\n",
       "      <td>v</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>15783</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>10088</td>\n",
       "      <td>10742</td>\n",
       "      <td>be</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>d000</td>\n",
       "      <td>d000.s000</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>d000.s000.t002</td>\n",
       "      <td>review</td>\n",
       "      <td>VERB</td>\n",
       "      <td>review%2:31:00::</td>\n",
       "      <td>review#v</td>\n",
       "      <td>v</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>look at again; examine again</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>review reexamine</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>d000</td>\n",
       "      <td>d000.s000</td>\n",
       "      <td>objectives</td>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>objective</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>objective#n</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>the goal intended to be attained (and which is...</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>aim object objective target</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>d000</td>\n",
       "      <td>d000.s000</td>\n",
       "      <td>benefit</td>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>benefit</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>benefit#n</td>\n",
       "      <td>n</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>financial assistance in time of need</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>benefit</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 text|@id text|sentence|@id text|sentence|instance  \\\n",
       "0           0     d000         d000.s000                   long   \n",
       "1           1     d000         d000.s000                   been   \n",
       "2           2     d000         d000.s000               reviewed   \n",
       "3           3     d000         d000.s000             objectives   \n",
       "4           4     d000         d000.s000                benefit   \n",
       "\n",
       "  text|sentence|instance|@id text|sentence|instance|@lemma  \\\n",
       "0             d000.s000.t000                          long   \n",
       "1             d000.s000.t001                            be   \n",
       "2             d000.s000.t002                        review   \n",
       "3             d000.s000.t003                     objective   \n",
       "4             d000.s000.t004                       benefit   \n",
       "\n",
       "  text|sentence|instance|@pos     lexelt|sense|@id lexelt|@item lexelt|@pos  \\\n",
       "0                         ADJ       long%3:00:02::       long#a           a   \n",
       "1                        VERB         be%2:42:03::         be#v           v   \n",
       "2                        VERB     review%2:31:00::     review#v           v   \n",
       "3                        NOUN  objective%1:09:00::  objective#n           n   \n",
       "4                        NOUN    benefit%1:21:00::    benefit#n           n   \n",
       "\n",
       "   lexelt|@sence_count_wn  lexelt|@sense_count_corpus  \\\n",
       "0                       9                           3   \n",
       "1                      13                          11   \n",
       "2                       5                           3   \n",
       "3                       2                           1   \n",
       "4                       3                           3   \n",
       "\n",
       "   lexelt|@word_example_count  \\\n",
       "0                         193   \n",
       "1                       15783   \n",
       "2                          22   \n",
       "3                          38   \n",
       "4                          31   \n",
       "\n",
       "                                 lexelt|sense|@gloss  \\\n",
       "0  primarily temporal sense; being or indicating ...   \n",
       "1  have the quality of being; (copula, used with ...   \n",
       "2                       look at again; examine again   \n",
       "3  the goal intended to be attained (and which is...   \n",
       "4               financial assistance in time of need   \n",
       "\n",
       "   lexelt|sense|@sense_example_count  lexelt|sense|@sense_freq  \\\n",
       "0                                102                       118   \n",
       "1                              10088                     10742   \n",
       "2                                 12                        13   \n",
       "3                                 38                        38   \n",
       "4                                 16                        16   \n",
       "\n",
       "          lexelt|sense|@synset  \\\n",
       "0                         long   \n",
       "1                           be   \n",
       "2             review reexamine   \n",
       "3  aim object objective target   \n",
       "4                      benefit   \n",
       "\n",
       "                                           sentences  \n",
       "0  How long has it been since you reviewed the ob...  \n",
       "1  How long has it been since you reviewed the ob...  \n",
       "2  How long has it been since you reviewed the ob...  \n",
       "3  How long has it been since you reviewed the ob...  \n",
       "4  How long has it been since you reviewed the ob...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if gpu_server == True:\n",
    "    df = pd.read_csv('data/semcor_df.csv')\n",
    "else:\n",
    "    df = pd.read_csv('/content/drive/MyDrive/semcor_belli/semcor_df.csv')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcDWQMTEHrGb",
    "outputId": "61c8afe1-6a62-41f1-8aab-9fccbbea4a49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VERB    88098\n",
       "NOUN    86668\n",
       "ADJ     31673\n",
       "ADV     18941\n",
       "Name: text|sentence|instance|@pos, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = df['text|sentence|instance|@pos'].value_counts()\n",
    "check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL-zph0cqUFE"
   },
   "source": [
    "Come ottimizzare (taglio concetti o taglio parole). Selezioni su set concetti + comuni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1j2E0fro9b2h"
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df['text|sentence|instance|@pos'] == 'VERB'].index)\n",
    "df = df.drop(df[df['text|sentence|instance|@pos'] == 'ADJ'].index)\n",
    "df = df.drop(df[df['text|sentence|instance|@pos'] == 'ADV'].index)\n",
    "#df = df.drop(df[df['text|sentence|instance|@pos'] == 'NOUN'].index)\n",
    "#df = df.drop(df[df['text|sentence|instance'] != 'have'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iq0nhx5k9q5L",
    "outputId": "9a013e10-9e4a-4631-cb9d-ff657866a57f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86668, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "I3I1muPVw1UU",
    "outputId": "3f233d02-151b-451e-ed2c-94d35237ae50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text|sentence|instance|@id</th>\n",
       "      <th>text|sentence|instance|@lemma</th>\n",
       "      <th>lexelt|sense|@id</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>objective</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d000.s000.t005</td>\n",
       "      <td>service</td>\n",
       "      <td>service%1:04:07::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d000.s000.t006</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d000.s001.t002</td>\n",
       "      <td>giveaway</td>\n",
       "      <td>giveaway%1:21:00::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220309</th>\n",
       "      <td>d183.s068.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>Kate 's all right''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220310</th>\n",
       "      <td>d183.s088.t000</td>\n",
       "      <td>vacation</td>\n",
       "      <td>vacation%1:28:00::</td>\n",
       "      <td>Well, we 're taking a little vacation, that 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220314</th>\n",
       "      <td>d183.s138.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>`` How 's Scotty''?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220315</th>\n",
       "      <td>d185.s034.t000</td>\n",
       "      <td>plunker</td>\n",
       "      <td>plunker%1:04:00::</td>\n",
       "      <td>No plunkers for him''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220316</th>\n",
       "      <td>d185.s082.t000</td>\n",
       "      <td>height</td>\n",
       "      <td>height%1:26:00::</td>\n",
       "      <td>Their heights, that is.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86668 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text|sentence|instance|@id text|sentence|instance|@lemma  \\\n",
       "3                  d000.s000.t003                     objective   \n",
       "4                  d000.s000.t004                       benefit   \n",
       "5                  d000.s000.t005                       service   \n",
       "6                  d000.s000.t006                       program   \n",
       "9                  d000.s001.t002                      giveaway   \n",
       "...                           ...                           ...   \n",
       "220309             d183.s068.t000                        person   \n",
       "220310             d183.s088.t000                      vacation   \n",
       "220314             d183.s138.t000                        person   \n",
       "220315             d185.s034.t000                       plunker   \n",
       "220316             d185.s082.t000                        height   \n",
       "\n",
       "           lexelt|sense|@id                                          sentences  \n",
       "3       objective%1:09:00::  How long has it been since you reviewed the ob...  \n",
       "4         benefit%1:21:00::  How long has it been since you reviewed the ob...  \n",
       "5         service%1:04:07::  How long has it been since you reviewed the ob...  \n",
       "6         program%1:09:01::  How long has it been since you reviewed the ob...  \n",
       "9        giveaway%1:21:00::  Have you permitted it to become a giveaway pro...  \n",
       "...                     ...                                                ...  \n",
       "220309     person%1:03:00::                               Kate 's all right''.  \n",
       "220310   vacation%1:28:00::  Well, we 're taking a little vacation, that 's...  \n",
       "220314     person%1:03:00::                                `` How 's Scotty''?  \n",
       "220315    plunker%1:04:00::                             No plunkers for him''.  \n",
       "220316     height%1:26:00::                            Their heights, that is.  \n",
       "\n",
       "[86668 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Unnamed: 0','text|@id','text|sentence|@id','text|sentence|instance','text|sentence|instance|@pos',\n",
    "                   'lexelt|@item','lexelt|@pos','lexelt|@sence_count_wn','lexelt|@sense_count_corpus','lexelt|@word_example_count',\n",
    "                   'lexelt|sense|@gloss','lexelt|sense|@sense_example_count','lexelt|sense|@sense_freq','lexelt|sense|@synset'],\n",
    "                  axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MDN5jIO_yfHX"
   },
   "outputs": [],
   "source": [
    "#df_sent = df_sent.set_index(df_sent['text|sentence|instance|@id'])\n",
    "#df_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "K-KRT4hFyvgG"
   },
   "outputs": [],
   "source": [
    "df2 = df1.rename(columns = {'lexelt|sense|@id': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "9zCUXNXD53EV",
    "outputId": "1f79f11a-f04a-4ae4-b37e-40b850341cc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text|sentence|instance|@id</th>\n",
       "      <th>text|sentence|instance|@lemma</th>\n",
       "      <th>target</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>objective</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d000.s000.t005</td>\n",
       "      <td>service</td>\n",
       "      <td>service%1:04:07::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d000.s000.t006</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d000.s001.t002</td>\n",
       "      <td>giveaway</td>\n",
       "      <td>giveaway%1:21:00::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220309</th>\n",
       "      <td>d183.s068.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>Kate 's all right''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220310</th>\n",
       "      <td>d183.s088.t000</td>\n",
       "      <td>vacation</td>\n",
       "      <td>vacation%1:28:00::</td>\n",
       "      <td>Well, we 're taking a little vacation, that 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220314</th>\n",
       "      <td>d183.s138.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>`` How 's Scotty''?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220315</th>\n",
       "      <td>d185.s034.t000</td>\n",
       "      <td>plunker</td>\n",
       "      <td>plunker%1:04:00::</td>\n",
       "      <td>No plunkers for him''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220316</th>\n",
       "      <td>d185.s082.t000</td>\n",
       "      <td>height</td>\n",
       "      <td>height%1:26:00::</td>\n",
       "      <td>Their heights, that is.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86668 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text|sentence|instance|@id text|sentence|instance|@lemma  \\\n",
       "3                  d000.s000.t003                     objective   \n",
       "4                  d000.s000.t004                       benefit   \n",
       "5                  d000.s000.t005                       service   \n",
       "6                  d000.s000.t006                       program   \n",
       "9                  d000.s001.t002                      giveaway   \n",
       "...                           ...                           ...   \n",
       "220309             d183.s068.t000                        person   \n",
       "220310             d183.s088.t000                      vacation   \n",
       "220314             d183.s138.t000                        person   \n",
       "220315             d185.s034.t000                       plunker   \n",
       "220316             d185.s082.t000                        height   \n",
       "\n",
       "                     target                                          sentences  \n",
       "3       objective%1:09:00::  How long has it been since you reviewed the ob...  \n",
       "4         benefit%1:21:00::  How long has it been since you reviewed the ob...  \n",
       "5         service%1:04:07::  How long has it been since you reviewed the ob...  \n",
       "6         program%1:09:01::  How long has it been since you reviewed the ob...  \n",
       "9        giveaway%1:21:00::  Have you permitted it to become a giveaway pro...  \n",
       "...                     ...                                                ...  \n",
       "220309     person%1:03:00::                               Kate 's all right''.  \n",
       "220310   vacation%1:28:00::  Well, we 're taking a little vacation, that 's...  \n",
       "220314     person%1:03:00::                                `` How 's Scotty''?  \n",
       "220315    plunker%1:04:00::                             No plunkers for him''.  \n",
       "220316     height%1:26:00::                            Their heights, that is.  \n",
       "\n",
       "[86668 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2CPd9ZK-avEl"
   },
   "outputs": [],
   "source": [
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "mL-efqoZaya7",
    "outputId": "15c70534-a6f6-49fb-b363-cfee922208e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text|sentence|instance|@id</th>\n",
       "      <th>text|sentence|instance|@lemma</th>\n",
       "      <th>target</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>objective</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s000.t005</td>\n",
       "      <td>service</td>\n",
       "      <td>service%1:04:07::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s000.t006</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s001.t002</td>\n",
       "      <td>giveaway</td>\n",
       "      <td>giveaway%1:21:00::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86663</th>\n",
       "      <td>d183.s068.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>Kate 's all right''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86664</th>\n",
       "      <td>d183.s088.t000</td>\n",
       "      <td>vacation</td>\n",
       "      <td>vacation%1:28:00::</td>\n",
       "      <td>Well, we 're taking a little vacation, that 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86665</th>\n",
       "      <td>d183.s138.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>`` How 's Scotty''?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86666</th>\n",
       "      <td>d185.s034.t000</td>\n",
       "      <td>plunker</td>\n",
       "      <td>plunker%1:04:00::</td>\n",
       "      <td>No plunkers for him''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86667</th>\n",
       "      <td>d185.s082.t000</td>\n",
       "      <td>height</td>\n",
       "      <td>height%1:26:00::</td>\n",
       "      <td>Their heights, that is.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86668 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text|sentence|instance|@id text|sentence|instance|@lemma  \\\n",
       "0                 d000.s000.t003                     objective   \n",
       "1                 d000.s000.t004                       benefit   \n",
       "2                 d000.s000.t005                       service   \n",
       "3                 d000.s000.t006                       program   \n",
       "4                 d000.s001.t002                      giveaway   \n",
       "...                          ...                           ...   \n",
       "86663             d183.s068.t000                        person   \n",
       "86664             d183.s088.t000                      vacation   \n",
       "86665             d183.s138.t000                        person   \n",
       "86666             d185.s034.t000                       plunker   \n",
       "86667             d185.s082.t000                        height   \n",
       "\n",
       "                    target                                          sentences  \n",
       "0      objective%1:09:00::  How long has it been since you reviewed the ob...  \n",
       "1        benefit%1:21:00::  How long has it been since you reviewed the ob...  \n",
       "2        service%1:04:07::  How long has it been since you reviewed the ob...  \n",
       "3        program%1:09:01::  How long has it been since you reviewed the ob...  \n",
       "4       giveaway%1:21:00::  Have you permitted it to become a giveaway pro...  \n",
       "...                    ...                                                ...  \n",
       "86663     person%1:03:00::                               Kate 's all right''.  \n",
       "86664   vacation%1:28:00::  Well, we 're taking a little vacation, that 's...  \n",
       "86665     person%1:03:00::                                `` How 's Scotty''?  \n",
       "86666    plunker%1:04:00::                             No plunkers for him''.  \n",
       "86667     height%1:26:00::                            Their heights, that is.  \n",
       "\n",
       "[86668 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fR3VgYg6MpB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNLurd3H7KaI",
    "outputId": "f06464e2-da55-4b05-e8c0-513b378f6048"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person%1:03:00::            6696\n",
       "group%1:03:00::             1328\n",
       "location%1:03:00::           989\n",
       "man%1:18:00::                429\n",
       "year%1:28:01::               409\n",
       "                            ... \n",
       "inclination%1:25:02::          1\n",
       "psychopomp%1:18:00::           1\n",
       "switch-hitter%1:18:00::        1\n",
       "ebbing%1:22:00::               1\n",
       "implementation%1:04:00::       1\n",
       "Name: target, Length: 15875, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_counts = df2[\"target\"].value_counts()\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1yV5c4XY9ZT",
    "outputId": "f807080a-2fab-4db7-8af6-361851a0e05b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text|sentence|instance|@id       0\n",
       "text|sentence|instance|@lemma    0\n",
       "target                           0\n",
       "sentences                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "KESBfLoRJ5gE",
    "outputId": "fe37ba6d-c843-421f-b891-161e2ba1ed22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text|sentence|instance|@id</th>\n",
       "      <th>text|sentence|instance|@lemma</th>\n",
       "      <th>target</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>objective</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s000.t006</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d000.s001.t003</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d000.s001.t006</td>\n",
       "      <td>goal</td>\n",
       "      <td>goal%1:09:00::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86661</th>\n",
       "      <td>d179.s025.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>`` What about Ballestre''?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86662</th>\n",
       "      <td>d179.s027.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>`` Precious.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86663</th>\n",
       "      <td>d183.s068.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>Kate 's all right''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86664</th>\n",
       "      <td>d183.s088.t000</td>\n",
       "      <td>vacation</td>\n",
       "      <td>vacation%1:28:00::</td>\n",
       "      <td>Well, we 're taking a little vacation, that 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86665</th>\n",
       "      <td>d183.s138.t000</td>\n",
       "      <td>person</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>`` How 's Scotty''?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54069 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text|sentence|instance|@id text|sentence|instance|@lemma  \\\n",
       "0                 d000.s000.t003                     objective   \n",
       "1                 d000.s000.t004                       benefit   \n",
       "3                 d000.s000.t006                       program   \n",
       "5                 d000.s001.t003                       program   \n",
       "6                 d000.s001.t006                          goal   \n",
       "...                          ...                           ...   \n",
       "86661             d179.s025.t000                        person   \n",
       "86662             d179.s027.t000                        person   \n",
       "86663             d183.s068.t000                        person   \n",
       "86664             d183.s088.t000                      vacation   \n",
       "86665             d183.s138.t000                        person   \n",
       "\n",
       "                    target                                          sentences  \n",
       "0      objective%1:09:00::  How long has it been since you reviewed the ob...  \n",
       "1        benefit%1:21:00::  How long has it been since you reviewed the ob...  \n",
       "3        program%1:09:01::  How long has it been since you reviewed the ob...  \n",
       "5        program%1:09:01::  Have you permitted it to become a giveaway pro...  \n",
       "6           goal%1:09:00::  Have you permitted it to become a giveaway pro...  \n",
       "...                    ...                                                ...  \n",
       "86661     person%1:03:00::                         `` What about Ballestre''?  \n",
       "86662     person%1:03:00::                                       `` Precious.  \n",
       "86663     person%1:03:00::                               Kate 's all right''.  \n",
       "86664   vacation%1:28:00::  Well, we 're taking a little vacation, that 's...  \n",
       "86665     person%1:03:00::                                `` How 's Scotty''?  \n",
       "\n",
       "[54069 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.groupby('target').filter(lambda x: len(x) >= 10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_CDVX8cjYTm",
    "outputId": "68de04fa-30e3-491c-fd35-90507d4b6132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text|sentence|instance|@id       object\n",
       "text|sentence|instance|@lemma    object\n",
       "target                           object\n",
       "sentences                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVQm54dGKX4R",
    "outputId": "b3d558b6-9225-4622-8472-e920f61a5feb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person        6696\n",
       "group         1328\n",
       "location       989\n",
       "man            566\n",
       "time           493\n",
       "              ... \n",
       "consumer        10\n",
       "safety          10\n",
       "oil             10\n",
       "regulation      10\n",
       "prospect        10\n",
       "Name: text|sentence|instance|@lemma, Length: 1352, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_counts = df2[\"text|sentence|instance|@lemma\"].value_counts()\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8EUrZACVyqF4"
   },
   "outputs": [],
   "source": [
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oa3NbbYyPGFR",
    "outputId": "e42322fc-f2ad-488d-dcbb-3432ea680807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text|sentence|instance|@id       0\n",
       "text|sentence|instance|@lemma    0\n",
       "target                           0\n",
       "sentences                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Pf1F8IDQPzxm"
   },
   "outputs": [],
   "source": [
    "#df3 = df2.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "N-JrYVDXQQEo"
   },
   "outputs": [],
   "source": [
    "#df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HPuNxrJyZB6s"
   },
   "outputs": [],
   "source": [
    "#filtered.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bueyqbajnkne",
    "outputId": "f0c2a69a-14fb-4283-e4a0-4b820fa0c911"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text|sentence|instance|@id         object\n",
       "text|sentence|instance|@lemma      object\n",
       "target                           category\n",
       "sentences                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"target\"] = df2[\"target\"].astype('category')\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "wKPiooI5nxON",
    "outputId": "746b90cc-6370-486f-a03e-e08a40648c7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text|sentence|instance|@id</th>\n",
       "      <th>text|sentence|instance|@lemma</th>\n",
       "      <th>target</th>\n",
       "      <th>sentences</th>\n",
       "      <th>target_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>objective</td>\n",
       "      <td>objective%1:09:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t004</td>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit%1:21:00::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s000.t006</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s001.t003</td>\n",
       "      <td>program</td>\n",
       "      <td>program%1:09:01::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s001.t006</td>\n",
       "      <td>goal</td>\n",
       "      <td>goal%1:09:00::</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text|sentence|instance|@id text|sentence|instance|@lemma  \\\n",
       "0             d000.s000.t003                     objective   \n",
       "1             d000.s000.t004                       benefit   \n",
       "2             d000.s000.t006                       program   \n",
       "3             d000.s001.t003                       program   \n",
       "4             d000.s001.t006                          goal   \n",
       "\n",
       "                target                                          sentences  \\\n",
       "0  objective%1:09:00::  How long has it been since you reviewed the ob...   \n",
       "1    benefit%1:21:00::  How long has it been since you reviewed the ob...   \n",
       "2    program%1:09:01::  How long has it been since you reviewed the ob...   \n",
       "3    program%1:09:01::  Have you permitted it to become a giveaway pro...   \n",
       "4       goal%1:09:00::  Have you permitted it to become a giveaway pro...   \n",
       "\n",
       "   target_enc  \n",
       "0        1011  \n",
       "1         135  \n",
       "2        1201  \n",
       "3        1201  \n",
       "4         644  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"target_enc\"] = df2[\"target\"].cat.codes\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxOqst_boKH-",
    "outputId": "597a65a0-0c27-40da-c1c8-607ab22b0d29"
   },
   "outputs": [],
   "source": [
    "#df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SWbBpOp_LTc3"
   },
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame()\n",
    "new_data['text'] = df2['sentences']\n",
    "new_data['labels'] = df2['target_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lsOrkXddL2WH",
    "outputId": "ee767a0d-1ed5-4843-ed89-56ff5d853a6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  How long has it been since you reviewed the ob...    1011\n",
       "1  How long has it been since you reviewed the ob...     135\n",
       "2  How long has it been since you reviewed the ob...    1201\n",
       "3  Have you permitted it to become a giveaway pro...    1201\n",
       "4  Have you permitted it to become a giveaway pro...     644"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og3kAgOPh8vq",
    "outputId": "1100a663-a94e-4ee2-acc7-f3199c8a164f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      object\n",
       "labels     int16\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "5v-yVYubUifl",
    "outputId": "0681dde3-44ed-40c8-d864-cc77880e94a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [len(sent) for sent in new_data['text']]\n",
    "pd.Series(sentences).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEANING AND NLP ANALYSIS OF TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:\n",
      " He had to look for other prospects, other motives until more conclusive evidence pointing to Johnston came to light.\n",
      "Sentence 1:\n",
      " Madden, with his investigation centered on the fraud, said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared.\n",
      "Sentence 2:\n",
      " Madden, with his investigation centered on the fraud, said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared.\n",
      "Sentence 3:\n",
      " Madden, with his investigation centered on the fraud, said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared.\n",
      "Sentence 4:\n",
      " Madden, with his investigation centered on the fraud, said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared.\n",
      "Sentence 5:\n",
      " Madden, with his investigation centered on the fraud, said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared.\n",
      "Sentence 6:\n",
      " Madden, with his investigation centered on the fraud, said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared.\n",
      "Sentence 7:\n",
      " Arthur Williams had to be located, they agreed.\n",
      "Sentence 8:\n",
      " He might have been in collusion with Johnston on the fraud; he might be Mrs. Meeker 's murderer or have played some part in her death.\n",
      "Sentence 9:\n",
      " He might have been in collusion with Johnston on the fraud; he might be Mrs. Meeker 's murderer or have played some part in her death.\n"
     ]
    }
   ],
   "source": [
    "for index,text in enumerate(new_data['text'][400:410]):\n",
    "  print('Sentence %d:\\n'%(index),text) #300:305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # For visualizations\n",
    "import matplotlib.pyplot as plt # For regular expressions\n",
    "import re # For handling string\n",
    "import string # For performing mathematical operations\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"aren't\": \"are not\",   \n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'s\":\"is\",\"'m\":\"am\",\"'re\":\"are\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\",\"'scuse\":\" excuse\" }\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "  def replace(match):\n",
    "    return contractions_dict[match.group(0)]\n",
    "  return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the plots\n",
    "new_data['text']=new_data['text'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['text']=new_data['text'].apply(lambda x: x.lower())\n",
    "new_data['text']=new_data['text'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "new_data['text']=new_data['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:\n",
      " he had to look for other prospects other motives until more conclusive evidence pointing to johnston came to light\n",
      "Sentence 1:\n",
      " madden with his investigation centered on the fraud said that tomorrow he would go to the bronx bank through which mrs meeker is checks to johnston had cleared\n",
      "Sentence 2:\n",
      " madden with his investigation centered on the fraud said that tomorrow he would go to the bronx bank through which mrs meeker is checks to johnston had cleared\n",
      "Sentence 3:\n",
      " madden with his investigation centered on the fraud said that tomorrow he would go to the bronx bank through which mrs meeker is checks to johnston had cleared\n",
      "Sentence 4:\n",
      " madden with his investigation centered on the fraud said that tomorrow he would go to the bronx bank through which mrs meeker is checks to johnston had cleared\n",
      "Sentence 5:\n",
      " madden with his investigation centered on the fraud said that tomorrow he would go to the bronx bank through which mrs meeker is checks to johnston had cleared\n",
      "Sentence 6:\n",
      " madden with his investigation centered on the fraud said that tomorrow he would go to the bronx bank through which mrs meeker is checks to johnston had cleared\n",
      "Sentence 7:\n",
      " arthur williams had to be located they agreed\n",
      "Sentence 8:\n",
      " he might have been in collusion with johnston on the fraud he might be mrs meeker is murderer or have played some part in her death\n",
      "Sentence 9:\n",
      " he might have been in collusion with johnston on the fraud he might be mrs meeker is murderer or have played some part in her death\n"
     ]
    }
   ],
   "source": [
    "for index,text in enumerate(new_data['text'][400:410]):\n",
    "  print('Sentence %d:\\n'%(index),text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK = set(new_data[\"text\"])\n",
    "#print(len(CHECK))   #17696 different sentences in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_sm')\n",
    "#text = list(new_data[\"text\"])\n",
    "#doc = str(text) \n",
    "#doc1 = nlp(doc)          #NLP PART ON GOOGLE COLAB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [len(sent) for sent in new_data['text']]\n",
    "pd.Series(sentences).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n"
     ]
    }
   ],
   "source": [
    "print(new_data['labels'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCoMFxhrT_HS"
   },
   "source": [
    "### THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "xAfyz5Uo7EnY"
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "b9614946527d4a84b7d2914abdca7638",
      "ba0a51f48f2846168d4941e9d0f1c4e9",
      "97f29e2e7ec74e959cd5f8c27f69a6e0",
      "e14974773ce748c98c9b27fdd14d17ac",
      "4bd6700290bf4208b7923a60e753e1dd",
      "2c27f976e73547558bfe56a22bf5abb0",
      "174b7ead6f4d4ef4a3dbc935cd0e1c82",
      "96454e6a5b50444eb69d6599d0603068",
      "1ea943039773429da68909ad7c553606",
      "305723de8e7244049928315a58e0b6e8",
      "ed2dc8c4000f475088a1d82a56493aa4",
      "81f8f43ed2bf4bbd829e4d4972de526a",
      "15c2626289b24f4481217dd20dfe49a7",
      "ed17dea5822b4ccf9fffc8b851b25988",
      "22d335ecfac347278a9b51fd5256ff01",
      "30065df54d6a431d934082573413697f",
      "2fbd22bed9854c48aa0306b97262e22f",
      "520a2b4ad663497b9510c601ec756350",
      "c502158f07fd4132b9acf603a036083a",
      "504095b955914b37b6e1faf94ca63dac",
      "f343e9f9ad8f470a8efecce10ccb7d2e",
      "529fadf0c6824eef8b717d3fc015b0b3",
      "3307cb82e9c3410ca2e1b3d70f34f842",
      "b2a38b769ba84d7e922140eba02be013"
     ]
    },
    "id": "V94HdiFML87L",
    "outputId": "e6cae774-716c-40ab-9bd6-2b71b830e472"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 200 #or 300 (depends)\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE  = 64\n",
    "VALID_BATCH_SIZE = 64\n",
    "LEARNING_RATE = 2e-5\n",
    "#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "cy1_w_3nMCsl"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation = True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long) #long\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAQHiq1D6jIG",
    "outputId": "2868f026-0652-4071-86b0-47fb14018d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (54069, 2)\n",
      "TRAIN Dataset: (40552, 2)\n",
      "TEST Dataset: (8110, 2)\n",
      "VALIDATION Dataset: (5407, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.75\n",
    "test_size  = 0.60\n",
    "\n",
    "train_data = new_data.sample(frac=train_size,random_state=200)\n",
    "eval_data  = new_data.drop(train_data.index)#.reset_index(drop=True)\n",
    "test_data  = eval_data.sample(frac=test_size,random_state=200)\n",
    "val_data   = eval_data.drop(test_data.index)\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data  = test_data.reset_index(drop=True)\n",
    "val_data   = val_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "print(\"VALIDATION Dataset: {}\".format(val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who is the owner</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>children scoring high in compulsivity were tho...</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>briefly we rolled over a paved road up to pak ...</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrs horowitz was in charge of diseases of the ...</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in man the normal level of iodine in the diet ...</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40547</th>\n",
       "      <td>by  bc the aegean was an area of common tongue...</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40548</th>\n",
       "      <td>he would cross to manhattan to harlem heights ...</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40549</th>\n",
       "      <td>moreover as communist power increases the enjo...</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40550</th>\n",
       "      <td>thus the transformation of adam smith is ideal...</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40551</th>\n",
       "      <td>when he had stored his stock in the great oak ...</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0                                       who is the owner    1043\n",
       "1      children scoring high in compulsivity were tho...    1393\n",
       "2      briefly we rolled over a paved road up to pak ...     856\n",
       "3      mrs horowitz was in charge of diseases of the ...    1567\n",
       "4      in man the normal level of iodine in the diet ...     771\n",
       "...                                                  ...     ...\n",
       "40547  by  bc the aegean was an area of common tongue...     350\n",
       "40548  he would cross to manhattan to harlem heights ...     951\n",
       "40549  moreover as communist power increases the enjo...     301\n",
       "40550  thus the transformation of adam smith is ideal...     398\n",
       "40551  when he had stored his stock in the great oak ...    1474\n",
       "\n",
       "[40552 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set   = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set    = MultiLabelDataset(test_data, tokenizer, MAX_LEN)\n",
    "validating_set = MultiLabelDataset(val_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ESBEi0L87up2"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader   = DataLoader(training_set, **train_params)\n",
    "testing_loader    = DataLoader(testing_set, **test_params)\n",
    "validating_loader = DataLoader(validating_set, **val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "19053ccc6bcc4312a3990f08747060c7",
      "271712fa9dd040e08df70f3e81d670f6",
      "3cbc4fd56ddc4626bb1d60292f3c1fae",
      "adbd2e21ba3c469d983451160cd1c8cb",
      "d18240ea41cd4461ac83bec357cfe163",
      "cdf61e485fd74e61a349fa0f4b85099e",
      "b93b5c0a092d497482f20743313c4da5",
      "39beff230cd440c69ee331bef858c567",
      "5c02c35152f44074b66cd4333c53ee3c",
      "ead17d90ba6946169c8f5f90ec009625",
      "cf5d703cd2d341ee8f8959fe863d9360",
      "b43095072da74bd89019c2ee41404205",
      "ac0b9fb6ca614ec0b1a72c4c1b625a0a",
      "b59b6733a9ca4efeb627ebf9a4c292da",
      "cb2c8a118c5340e78ad5cbb723e19cf2",
      "f7eb4c98104645489338ba7dc9e75b4d"
     ]
    },
    "id": "0nD_zCqYMaVv",
    "outputId": "97ec239f-f601-4d09-a0ff-191d6b88b502"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoBERTaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1729, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from transformers import DistilBertModel\n",
    "#\n",
    "#class DistilBERTClass(torch.nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(DistilBERTClass, self).__init__()\n",
    "#        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "#        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "#        self.dropout = torch.nn.Dropout(0.1)\n",
    "#        self.classifier = torch.nn.Linear(768, 5485) #24083, #181\n",
    "#\n",
    "#    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "#        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#        hidden_state = output_1[0]\n",
    "#        pooler = hidden_state[:, 0]\n",
    "#        pooler = self.pre_classifier(pooler)\n",
    "#        pooler = torch.nn.Tanh()(pooler)\n",
    "#        pooler = self.dropout(pooler)\n",
    "#        output = self.classifier(pooler)\n",
    "#        return output\n",
    "#\n",
    "#model = DistilBERTClass()\n",
    "#model.to(device)\n",
    "\n",
    "from transformers import RobertaModel\n",
    "\n",
    "class RoBERTaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RoBERTaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        #self.classifier_hid = torch.nn.Linear(768, 1512)\n",
    "        #self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.classifier = torch.nn.Linear(768, 1729)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        #pooler = self.classifier_hid(pooler)\n",
    "        #pooler = self.dropout(pooler)\n",
    "        #pooler = torch.nn.ReLU()(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = RoBERTaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "uMqVo6UJMyun"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples): #scheduler,\n",
    "    model = model.train() \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for _,data in enumerate(data_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, dim=1) #max\n",
    "        loss = loss_fn(outputs, targets) # get loss\n",
    "        \n",
    "        correct_predictions += torch.sum(preds==targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval() #Evaluation mode\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _,data in enumerate(data_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds==targets)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_model(model, data_loaders_train, data_loader_test, train_sizes, test_sizes, device, n_epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.001)\n",
    "    loss_fn   = torch.nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{n_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_acc, train_loss = train_epoch(model, training_loader, loss_fn, \n",
    "                                            optimizer, device, scheduler, train_data.shape[0]) #scheduler,\n",
    "        \n",
    "        print(f'Train loss {train_loss}, accuracy {train_acc}') #accuracy {train_acc}\n",
    "        \n",
    "        val_acc, val_loss = eval_model(model, testing_loader, loss_fn, device, test_data.shape[0])\n",
    "        \n",
    "        print(f'Val loss {val_loss}, accuracy {val_acc}') # accuracy {val_acc}\n",
    "        print()\n",
    "        \n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "            best_accuracy = val_acc\n",
    "            \n",
    "    print(f'Best val accuracy: {best_accuracy}')\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "Train loss 6.557614467121449, accuracy 0.1268987966068258\n",
      "Val loss 6.189224532270056, accuracy 0.1409371146732429\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "Train loss 5.986697509085718, accuracy 0.15089268100217004\n",
      "Val loss 5.739165542632576, accuracy 0.16646115906288533\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "Train loss 5.564307567072968, accuracy 0.17708127835865062\n",
      "Val loss 5.416635610925869, accuracy 0.18668310727496917\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "Train loss 5.230245818099013, accuracy 0.19986683764056026\n",
      "Val loss 5.163879999025601, accuracy 0.20221948212083846\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "Train loss 4.944898972751966, accuracy 0.2201864273032156\n",
      "Val loss 4.969417147749052, accuracy 0.20900123304562268\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "Train loss 4.7318246202890055, accuracy 0.23547543894259224\n",
      "Val loss 4.9656818720299425, accuracy 0.2091245376078915\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "Train loss 4.739911933050546, accuracy 0.2340205168672322\n",
      "Val loss 4.962469780538965, accuracy 0.20974106041923551\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "Train loss 4.72196656559544, accuracy 0.2363138686131387\n",
      "Val loss 4.960531347379909, accuracy 0.21048088779284832\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "Train loss 4.722962214367623, accuracy 0.23725093706845532\n",
      "Val loss 4.9582763807041434, accuracy 0.21072749691738593\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "Train loss 4.7185510126198125, accuracy 0.23668376405602684\n",
      "Val loss 4.957710288641021, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "Train loss 4.718839908247866, accuracy 0.23707831919510752\n",
      "Val loss 4.958854228492797, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "Train loss 4.722092207673972, accuracy 0.23562339711974747\n",
      "Val loss 4.957540988922119, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "Train loss 4.719292227402095, accuracy 0.23532748076543697\n",
      "Val loss 4.958065040468231, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "Train loss 4.720885660370065, accuracy 0.2365604655750641\n",
      "Val loss 4.956920835915513, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "Train loss 4.716771426261036, accuracy 0.23665910435983428\n",
      "Val loss 4.957813636524471, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "Train loss 4.7194203292533805, accuracy 0.2373002564608404\n",
      "Val loss 4.957658001757044, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "Train loss 4.7220154320027925, accuracy 0.2348836062339712\n",
      "Val loss 4.957860443535752, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "Train loss 4.721303406197942, accuracy 0.2383359637009272\n",
      "Val loss 4.957919578852616, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "Train loss 4.728285919228563, accuracy 0.23715229828368514\n",
      "Val loss 4.958888605823667, accuracy 0.21097410604192354\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "Train loss 4.721392894392886, accuracy 0.23796606825803907\n",
      "Val loss 4.956863129232812, accuracy 0.21097410604192354\n",
      "\n",
      "Best val accuracy: 0.21097410604192354\n",
      "CPU times: user 1h 54min 17s, sys: 41min 37s, total: 2h 35min 54s\n",
      "Wall time: 2h 35min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_model, history = train_model(model, training_loader, testing_loader, train_data.shape[0], test_data.shape[0],\n",
    "                                  device, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(18,6))\n",
    "    ax1.plot(history['train_loss'], label='train loss')\n",
    "    ax1.plot(history['val_loss'], label='validation loss')\n",
    "    \n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax1.set_ylim([1.00,5.00])\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    \n",
    "    ax2.plot(history['train_acc'], label='train accuracy')\n",
    "    ax2.plot(history['val_acc'], label='validation accuracy')\n",
    "    \n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2.set_ylim([0.00,1.00])\n",
    "    ax2.legend()\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    \n",
    "    fig.suptitle('Training History')\n",
    "    \n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "    with torch.no_grad():\n",
    "        for _,data in enumerate(data_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(targets)\n",
    "    predictions = torch.as_tensor(predictions).cpu()\n",
    "    real_values = torch.as_tensor(real_values).cpu()\n",
    "    \n",
    "    return predictions, real_values\n",
    "\n",
    "y_pred, y_test = get_predictions(model, validating_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.22      0.40      0.29         5\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         5\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         5\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         4\n",
      "          27       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         3\n",
      "          32       0.25      0.55      0.34        11\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         3\n",
      "          41       0.29      0.33      0.31         6\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         7\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.19      0.67      0.30         6\n",
      "          54       0.08      0.43      0.13         7\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         4\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         3\n",
      "          64       0.00      0.00      0.00         3\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         5\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         4\n",
      "          75       0.10      0.39      0.16        18\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         4\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.50      0.25      0.33         4\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         3\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         3\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         4\n",
      "          93       0.00      0.00      0.00         3\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         4\n",
      "          99       0.00      0.00      0.00         9\n",
      "         100       0.33      0.38      0.35         8\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         1\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         2\n",
      "         109       0.00      0.00      0.00         2\n",
      "         110       0.00      0.00      0.00         2\n",
      "         111       0.00      0.00      0.00         4\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         4\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         2\n",
      "         121       0.00      0.00      0.00         2\n",
      "         122       0.00      0.00      0.00         3\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.00      0.00      0.00         2\n",
      "         127       0.00      0.00      0.00         2\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         3\n",
      "         133       0.00      0.00      0.00         2\n",
      "         134       0.00      0.00      0.00         4\n",
      "         136       0.00      0.00      0.00         2\n",
      "         137       0.00      0.00      0.00         3\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         2\n",
      "         141       0.00      0.00      0.00         4\n",
      "         142       0.00      0.00      0.00         3\n",
      "         143       0.00      0.00      0.00         4\n",
      "         144       0.00      0.00      0.00         2\n",
      "         145       0.00      0.00      0.00         1\n",
      "         147       0.10      0.25      0.14         8\n",
      "         149       0.00      0.00      0.00         2\n",
      "         151       0.00      0.00      0.00         2\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         2\n",
      "         154       0.00      0.00      0.00         4\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       0.05      0.09      0.06        11\n",
      "         158       0.00      0.00      0.00         2\n",
      "         159       0.00      0.00      0.00         3\n",
      "         160       0.00      0.00      0.00         2\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         4\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         3\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         5\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       0.00      0.00      0.00         2\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         2\n",
      "         177       0.00      0.00      0.00         4\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         2\n",
      "         182       0.00      0.00      0.00         1\n",
      "         183       0.00      0.00      0.00         2\n",
      "         184       0.00      0.00      0.00         2\n",
      "         186       0.00      0.00      0.00         2\n",
      "         187       0.00      0.00      0.00         2\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         1\n",
      "         190       0.14      0.75      0.24         4\n",
      "         191       0.00      0.00      0.00         6\n",
      "         192       0.00      0.00      0.00         3\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00        12\n",
      "         197       0.00      0.00      0.00         3\n",
      "         198       0.00      0.00      0.00         2\n",
      "         199       0.00      0.00      0.00         2\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         2\n",
      "         202       0.00      0.00      0.00         5\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       0.20      0.75      0.32         4\n",
      "         205       0.08      0.17      0.11         6\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         2\n",
      "         208       0.00      0.00      0.00         6\n",
      "         210       0.19      0.91      0.31        11\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       0.00      0.00      0.00         4\n",
      "         213       0.00      0.00      0.00         2\n",
      "         214       0.00      0.00      0.00         3\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         7\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         2\n",
      "         219       0.00      0.00      0.00         3\n",
      "         220       0.00      0.00      0.00         2\n",
      "         222       0.00      0.00      0.00         2\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         2\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.15      0.33      0.21        15\n",
      "         231       0.00      0.00      0.00         7\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         3\n",
      "         234       0.00      0.00      0.00         2\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         5\n",
      "         240       0.25      0.12      0.17         8\n",
      "         241       0.00      0.00      0.00         2\n",
      "         243       0.00      0.00      0.00         3\n",
      "         244       0.00      0.00      0.00         6\n",
      "         245       0.00      0.00      0.00         4\n",
      "         246       0.08      0.23      0.12        13\n",
      "         247       0.00      0.00      0.00         4\n",
      "         249       0.00      0.00      0.00         3\n",
      "         250       0.00      0.00      0.00         3\n",
      "         251       0.00      0.00      0.00         2\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         1\n",
      "         255       0.00      0.00      0.00         1\n",
      "         257       0.00      0.00      0.00         2\n",
      "         259       0.00      0.00      0.00         7\n",
      "         261       0.00      0.00      0.00         3\n",
      "         263       0.00      0.00      0.00         5\n",
      "         264       0.00      0.00      0.00         4\n",
      "         265       0.00      0.00      0.00         2\n",
      "         266       0.00      0.00      0.00         3\n",
      "         267       0.33      0.11      0.17         9\n",
      "         268       0.00      0.00      0.00         5\n",
      "         269       0.00      0.00      0.00         2\n",
      "         270       0.00      0.00      0.00         5\n",
      "         272       0.50      0.25      0.33         4\n",
      "         275       0.00      0.00      0.00         2\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         2\n",
      "         278       0.00      0.00      0.00         4\n",
      "         279       0.00      0.00      0.00         2\n",
      "         280       0.00      0.00      0.00         5\n",
      "         281       0.00      0.00      0.00         3\n",
      "         282       0.00      0.00      0.00         2\n",
      "         283       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         9\n",
      "         285       0.00      0.00      0.00         4\n",
      "         286       0.00      0.00      0.00         2\n",
      "         287       0.00      0.00      0.00         2\n",
      "         288       0.00      0.00      0.00         2\n",
      "         289       0.00      0.00      0.00         2\n",
      "         290       0.00      0.00      0.00         2\n",
      "         292       0.00      0.00      0.00         2\n",
      "         294       0.00      0.00      0.00         1\n",
      "         295       0.00      0.00      0.00         6\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       0.00      0.00      0.00         3\n",
      "         299       0.00      0.00      0.00         1\n",
      "         300       0.00      0.00      0.00         1\n",
      "         301       0.00      0.00      0.00         7\n",
      "         302       0.00      0.00      0.00         2\n",
      "         303       0.00      0.00      0.00         1\n",
      "         304       0.00      0.00      0.00         2\n",
      "         305       0.00      0.00      0.00         2\n",
      "         306       0.00      0.00      0.00         2\n",
      "         307       0.00      0.00      0.00         1\n",
      "         309       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         2\n",
      "         311       0.00      0.00      0.00         2\n",
      "         312       0.00      0.00      0.00         1\n",
      "         313       0.00      0.00      0.00         3\n",
      "         315       0.00      0.00      0.00         2\n",
      "         317       0.00      0.00      0.00         3\n",
      "         318       0.00      0.00      0.00         1\n",
      "         319       0.00      0.00      0.00         1\n",
      "         320       0.00      0.00      0.00         1\n",
      "         321       0.00      0.00      0.00         2\n",
      "         323       0.00      0.00      0.00         2\n",
      "         324       0.00      0.00      0.00         1\n",
      "         325       0.00      0.00      0.00         1\n",
      "         326       0.00      0.00      0.00         2\n",
      "         327       0.00      0.00      0.00         1\n",
      "         328       0.00      0.00      0.00         1\n",
      "         329       0.00      0.00      0.00         1\n",
      "         330       0.00      0.00      0.00         1\n",
      "         331       0.50      0.25      0.33         4\n",
      "         332       0.12      0.50      0.19        12\n",
      "         333       0.00      0.00      0.00         1\n",
      "         334       0.07      0.80      0.12         5\n",
      "         336       0.00      0.00      0.00         1\n",
      "         337       0.00      0.00      0.00         2\n",
      "         339       0.17      0.25      0.20         4\n",
      "         340       0.00      0.00      0.00         1\n",
      "         341       0.00      0.00      0.00         1\n",
      "         342       0.00      0.00      0.00         4\n",
      "         343       0.00      0.00      0.00         2\n",
      "         344       0.00      0.00      0.00         1\n",
      "         347       0.00      0.00      0.00         1\n",
      "         348       0.00      0.00      0.00         2\n",
      "         349       0.00      0.00      0.00         1\n",
      "         350       0.00      0.00      0.00         2\n",
      "         351       0.00      0.00      0.00         1\n",
      "         352       0.00      0.00      0.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         355       0.00      0.00      0.00         1\n",
      "         356       0.00      0.00      0.00         2\n",
      "         357       0.00      0.00      0.00         1\n",
      "         360       0.00      0.00      0.00         2\n",
      "         361       0.00      0.00      0.00         2\n",
      "         362       0.00      0.00      0.00         1\n",
      "         363       0.12      0.30      0.17        10\n",
      "         364       0.00      0.00      0.00         2\n",
      "         365       0.00      0.00      0.00         2\n",
      "         367       0.11      0.38      0.17        16\n",
      "         368       0.00      0.00      0.00         6\n",
      "         369       0.00      0.00      0.00         2\n",
      "         370       0.00      0.00      0.00         8\n",
      "         371       0.00      0.00      0.00         1\n",
      "         372       0.00      0.00      0.00         4\n",
      "         373       0.00      0.00      0.00         2\n",
      "         377       0.00      0.00      0.00         3\n",
      "         378       0.00      0.00      0.00         1\n",
      "         379       0.00      0.00      0.00         3\n",
      "         384       0.00      0.00      0.00         1\n",
      "         385       0.00      0.00      0.00         1\n",
      "         387       0.00      0.00      0.00         1\n",
      "         389       0.00      0.00      0.00         2\n",
      "         390       0.00      0.00      0.00         2\n",
      "         392       0.00      0.00      0.00         1\n",
      "         393       0.00      0.00      0.00         2\n",
      "         395       0.00      0.00      0.00         1\n",
      "         396       0.00      0.00      0.00         3\n",
      "         397       0.00      0.00      0.00         6\n",
      "         398       0.00      0.00      0.00         5\n",
      "         399       0.00      0.00      0.00         2\n",
      "         400       0.00      0.00      0.00         7\n",
      "         402       0.00      0.00      0.00         6\n",
      "         403       0.00      0.00      0.00         3\n",
      "         404       0.00      0.00      0.00         2\n",
      "         405       0.00      0.00      0.00         2\n",
      "         406       0.00      0.00      0.00         2\n",
      "         407       0.00      0.00      0.00         4\n",
      "         408       0.00      0.00      0.00         8\n",
      "         409       0.00      0.00      0.00         2\n",
      "         410       0.00      0.00      0.00         3\n",
      "         412       0.00      0.00      0.00         2\n",
      "         413       0.00      0.00      0.00         1\n",
      "         415       0.00      0.00      0.00         1\n",
      "         418       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         2\n",
      "         421       0.00      0.00      0.00         1\n",
      "         422       0.00      0.00      0.00         4\n",
      "         423       0.00      0.00      0.00         3\n",
      "         424       0.00      0.00      0.00         4\n",
      "         425       0.00      0.00      0.00         4\n",
      "         426       0.00      0.00      0.00         3\n",
      "         427       0.00      0.00      0.00         2\n",
      "         429       0.00      0.00      0.00         2\n",
      "         430       0.00      0.00      0.00         2\n",
      "         431       0.00      0.00      0.00         1\n",
      "         432       0.50      0.12      0.20         8\n",
      "         433       0.00      0.00      0.00         1\n",
      "         434       1.00      0.25      0.40         4\n",
      "         436       0.00      0.00      0.00         1\n",
      "         437       0.46      0.43      0.44        14\n",
      "         438       0.00      0.00      0.00         7\n",
      "         439       0.00      0.00      0.00         1\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       0.00      0.00      0.00         2\n",
      "         442       0.00      0.00      0.00         5\n",
      "         443       0.00      0.00      0.00         2\n",
      "         445       0.00      0.00      0.00         1\n",
      "         446       0.00      0.00      0.00         1\n",
      "         448       0.00      0.00      0.00         2\n",
      "         449       0.00      0.00      0.00         2\n",
      "         450       0.00      0.00      0.00         2\n",
      "         451       0.00      0.00      0.00         3\n",
      "         452       0.00      0.00      0.00         1\n",
      "         453       0.00      0.00      0.00         2\n",
      "         454       0.00      0.00      0.00         1\n",
      "         455       0.00      0.00      0.00         1\n",
      "         457       0.00      0.00      0.00         1\n",
      "         458       0.50      0.50      0.50         2\n",
      "         459       0.00      0.00      0.00         3\n",
      "         461       0.00      0.00      0.00         5\n",
      "         462       0.00      0.00      0.00         3\n",
      "         463       0.00      0.00      0.00         1\n",
      "         464       0.00      0.00      0.00         3\n",
      "         465       0.00      0.00      0.00         1\n",
      "         466       0.00      0.00      0.00         7\n",
      "         467       0.00      0.00      0.00         1\n",
      "         468       0.00      0.00      0.00         1\n",
      "         469       0.00      0.00      0.00         4\n",
      "         470       0.00      0.00      0.00        10\n",
      "         471       0.00      0.00      0.00         1\n",
      "         472       0.00      0.00      0.00         3\n",
      "         473       0.27      0.80      0.40         5\n",
      "         475       0.00      0.00      0.00         2\n",
      "         477       0.00      0.00      0.00         2\n",
      "         478       1.00      0.20      0.33         5\n",
      "         479       0.00      0.00      0.00         2\n",
      "         480       0.12      0.40      0.18         5\n",
      "         481       0.00      0.00      0.00         2\n",
      "         482       0.00      0.00      0.00         1\n",
      "         483       0.00      0.00      0.00         2\n",
      "         484       0.00      0.00      0.00         3\n",
      "         485       0.00      0.00      0.00         3\n",
      "         486       0.00      0.00      0.00         3\n",
      "         487       0.67      0.50      0.57         4\n",
      "         488       0.00      0.00      0.00         4\n",
      "         489       0.00      0.00      0.00         2\n",
      "         490       0.00      0.00      0.00         3\n",
      "         492       0.00      0.00      0.00         1\n",
      "         493       0.00      0.00      0.00         2\n",
      "         495       0.00      0.00      0.00         1\n",
      "         496       0.00      0.00      0.00         2\n",
      "         497       0.00      0.00      0.00         4\n",
      "         498       0.00      0.00      0.00         1\n",
      "         499       0.00      0.00      0.00         3\n",
      "         500       0.00      0.00      0.00         2\n",
      "         501       0.00      0.00      0.00         3\n",
      "         503       0.00      0.00      0.00         2\n",
      "         504       0.00      0.00      0.00         2\n",
      "         505       0.00      0.00      0.00         8\n",
      "         506       0.00      0.00      0.00         5\n",
      "         507       0.00      0.00      0.00         4\n",
      "         508       0.00      0.00      0.00         3\n",
      "         509       0.00      0.00      0.00         1\n",
      "         510       0.00      0.00      0.00         3\n",
      "         512       0.00      0.00      0.00         3\n",
      "         513       0.00      0.00      0.00         1\n",
      "         514       0.00      0.00      0.00         2\n",
      "         515       0.00      0.00      0.00         2\n",
      "         516       0.00      0.00      0.00         1\n",
      "         518       0.00      0.00      0.00         2\n",
      "         519       0.00      0.00      0.00         3\n",
      "         520       0.00      0.00      0.00         5\n",
      "         521       0.00      0.00      0.00         6\n",
      "         522       0.00      0.00      0.00         9\n",
      "         523       0.00      0.00      0.00         3\n",
      "         524       0.00      0.00      0.00         1\n",
      "         525       0.00      0.00      0.00         4\n",
      "         526       0.00      0.00      0.00         1\n",
      "         527       0.00      0.00      0.00         3\n",
      "         528       0.00      0.00      0.00         3\n",
      "         530       0.00      0.00      0.00         3\n",
      "         531       0.00      0.00      0.00         1\n",
      "         532       0.00      0.00      0.00         2\n",
      "         533       0.24      0.52      0.33        23\n",
      "         534       0.00      0.00      0.00         2\n",
      "         535       0.00      0.00      0.00         1\n",
      "         536       0.31      0.38      0.34        13\n",
      "         537       0.00      0.00      0.00         5\n",
      "         538       0.00      0.00      0.00         8\n",
      "         539       0.00      0.00      0.00         2\n",
      "         540       0.00      0.00      0.00         7\n",
      "         541       0.00      0.00      0.00         1\n",
      "         542       0.00      0.00      0.00         3\n",
      "         543       0.00      0.00      0.00         1\n",
      "         544       0.00      0.00      0.00         2\n",
      "         545       0.00      0.00      0.00         1\n",
      "         546       0.00      0.00      0.00         2\n",
      "         547       0.00      0.00      0.00         9\n",
      "         548       0.00      0.00      0.00         7\n",
      "         549       0.11      0.33      0.17         3\n",
      "         550       0.00      0.00      0.00         4\n",
      "         551       0.00      0.00      0.00         1\n",
      "         552       0.00      0.00      0.00         3\n",
      "         554       0.67      0.29      0.40         7\n",
      "         555       0.00      0.00      0.00         6\n",
      "         556       0.00      0.00      0.00         1\n",
      "         557       0.00      0.00      0.00         2\n",
      "         558       0.00      0.00      0.00         2\n",
      "         559       0.00      0.00      0.00         2\n",
      "         560       0.00      0.00      0.00         4\n",
      "         561       0.00      0.00      0.00         5\n",
      "         562       0.00      0.00      0.00         3\n",
      "         563       0.00      0.00      0.00         2\n",
      "         565       0.00      0.00      0.00         1\n",
      "         566       0.00      0.00      0.00         2\n",
      "         567       0.00      0.00      0.00         5\n",
      "         568       0.00      0.00      0.00         4\n",
      "         569       0.00      0.00      0.00         2\n",
      "         570       0.00      0.00      0.00         1\n",
      "         572       0.00      0.00      0.00         4\n",
      "         573       0.00      0.00      0.00         1\n",
      "         574       0.00      0.00      0.00         1\n",
      "         575       0.00      0.00      0.00         3\n",
      "         576       0.12      0.33      0.17         6\n",
      "         577       0.00      0.00      0.00         1\n",
      "         578       0.00      0.00      0.00         1\n",
      "         579       0.00      0.00      0.00         3\n",
      "         580       0.00      0.00      0.00         2\n",
      "         581       0.00      0.00      0.00         6\n",
      "         583       0.00      0.00      0.00         6\n",
      "         584       0.00      0.00      0.00         2\n",
      "         585       0.00      0.00      0.00         3\n",
      "         586       0.00      0.00      0.00         4\n",
      "         587       0.00      0.00      0.00         2\n",
      "         588       0.00      0.00      0.00         1\n",
      "         589       0.00      0.00      0.00         1\n",
      "         590       0.00      0.00      0.00         1\n",
      "         591       0.00      0.00      0.00         1\n",
      "         592       0.00      0.00      0.00         5\n",
      "         593       0.00      0.00      0.00         1\n",
      "         594       0.00      0.00      0.00         2\n",
      "         597       0.00      0.00      0.00         1\n",
      "         598       0.00      0.00      0.00         1\n",
      "         599       0.00      0.00      0.00         4\n",
      "         600       0.00      0.00      0.00         4\n",
      "         601       0.00      0.00      0.00         6\n",
      "         602       0.19      0.50      0.27         6\n",
      "         603       0.00      0.00      0.00         2\n",
      "         604       0.00      0.00      0.00         1\n",
      "         606       0.00      0.00      0.00         3\n",
      "         608       0.00      0.00      0.00         2\n",
      "         609       0.00      0.00      0.00         1\n",
      "         610       0.00      0.00      0.00         3\n",
      "         611       0.28      1.00      0.43        10\n",
      "         614       0.00      0.00      0.00         2\n",
      "         615       0.00      0.00      0.00         1\n",
      "         616       0.00      0.00      0.00         3\n",
      "         617       0.00      0.00      0.00         2\n",
      "         618       0.00      0.00      0.00         1\n",
      "         619       0.00      0.00      0.00         4\n",
      "         620       0.40      0.22      0.29         9\n",
      "         622       0.00      0.00      0.00         1\n",
      "         623       0.00      0.00      0.00         1\n",
      "         624       0.00      0.00      0.00         5\n",
      "         625       0.00      0.00      0.00         3\n",
      "         626       0.00      0.00      0.00         1\n",
      "         627       0.00      0.00      0.00         1\n",
      "         628       0.00      0.00      0.00         4\n",
      "         629       0.00      0.00      0.00         3\n",
      "         630       0.00      0.00      0.00         1\n",
      "         631       0.00      0.00      0.00         3\n",
      "         632       0.00      0.00      0.00         1\n",
      "         635       0.00      0.00      0.00         3\n",
      "         636       0.00      0.00      0.00         3\n",
      "         637       0.00      0.00      0.00         1\n",
      "         638       0.30      1.00      0.46         3\n",
      "         639       0.25      0.33      0.29         3\n",
      "         640       0.00      0.00      0.00         3\n",
      "         641       0.00      0.00      0.00         2\n",
      "         642       0.00      0.00      0.00         4\n",
      "         644       0.00      0.00      0.00         6\n",
      "         645       0.17      0.80      0.29        10\n",
      "         646       0.00      0.00      0.00         3\n",
      "         647       0.00      0.00      0.00         1\n",
      "         648       0.10      0.31      0.15        13\n",
      "         649       0.00      0.00      0.00         3\n",
      "         650       0.00      0.00      0.00         2\n",
      "         651       0.00      0.00      0.00         2\n",
      "         652       0.00      0.00      0.00         2\n",
      "         653       0.00      0.00      0.00         1\n",
      "         654       0.00      0.00      0.00         1\n",
      "         655       0.00      0.00      0.00         2\n",
      "         656       0.00      0.00      0.00         6\n",
      "         657       0.22      0.57      0.31       134\n",
      "         658       0.00      0.00      0.00         4\n",
      "         659       0.00      0.00      0.00         1\n",
      "         660       0.00      0.00      0.00         1\n",
      "         662       0.00      0.00      0.00         1\n",
      "         663       0.00      0.00      0.00         4\n",
      "         664       0.00      0.00      0.00         4\n",
      "         665       0.00      0.00      0.00         1\n",
      "         666       0.20      0.33      0.25         6\n",
      "         667       0.00      0.00      0.00         4\n",
      "         668       0.00      0.00      0.00         2\n",
      "         669       0.14      0.21      0.17        19\n",
      "         670       0.00      0.00      0.00         5\n",
      "         671       0.00      0.00      0.00         2\n",
      "         673       0.00      0.00      0.00         4\n",
      "         674       0.29      0.50      0.36        16\n",
      "         675       0.00      0.00      0.00         1\n",
      "         676       0.00      0.00      0.00         1\n",
      "         677       0.00      0.00      0.00         4\n",
      "         678       0.00      0.00      0.00         1\n",
      "         679       0.00      0.00      0.00         4\n",
      "         680       0.00      0.00      0.00         1\n",
      "         681       0.00      0.00      0.00         1\n",
      "         683       0.00      0.00      0.00         1\n",
      "         685       0.00      0.00      0.00         1\n",
      "         686       0.00      0.00      0.00         3\n",
      "         687       0.00      0.00      0.00         6\n",
      "         688       0.00      0.00      0.00         1\n",
      "         689       0.00      0.00      0.00         3\n",
      "         690       0.00      0.00      0.00         2\n",
      "         691       0.00      0.00      0.00         1\n",
      "         692       0.00      0.00      0.00         2\n",
      "         693       0.00      0.00      0.00         2\n",
      "         694       0.00      0.00      0.00         1\n",
      "         695       0.00      0.00      0.00         2\n",
      "         696       0.00      0.00      0.00         2\n",
      "         698       0.00      0.00      0.00         1\n",
      "         699       0.00      0.00      0.00         6\n",
      "         700       0.00      0.00      0.00         6\n",
      "         703       0.00      0.00      0.00         3\n",
      "         704       0.00      0.00      0.00         1\n",
      "         705       0.00      0.00      0.00         3\n",
      "         706       0.00      0.00      0.00         2\n",
      "         707       0.47      0.57      0.52        14\n",
      "         708       0.00      0.00      0.00         1\n",
      "         709       0.00      0.00      0.00         3\n",
      "         710       0.13      0.33      0.19         6\n",
      "         711       0.00      0.00      0.00         1\n",
      "         712       0.15      0.53      0.24        15\n",
      "         713       0.00      0.00      0.00         1\n",
      "         714       0.00      0.00      0.00         2\n",
      "         715       0.00      0.00      0.00         4\n",
      "         716       0.00      0.00      0.00         1\n",
      "         717       1.00      0.14      0.25         7\n",
      "         718       0.00      0.00      0.00         4\n",
      "         719       0.00      0.00      0.00         1\n",
      "         720       0.00      0.00      0.00         1\n",
      "         722       0.09      0.45      0.14        11\n",
      "         723       0.00      0.00      0.00         1\n",
      "         725       0.00      0.00      0.00         2\n",
      "         726       0.00      0.00      0.00         2\n",
      "         727       0.00      0.00      0.00         1\n",
      "         728       0.00      0.00      0.00         1\n",
      "         729       0.00      0.00      0.00         1\n",
      "         730       0.00      0.00      0.00         1\n",
      "         731       0.00      0.00      0.00         3\n",
      "         732       0.00      0.00      0.00         1\n",
      "         733       0.00      0.00      0.00         5\n",
      "         735       0.00      0.00      0.00         4\n",
      "         736       0.00      0.00      0.00         2\n",
      "         737       0.11      0.60      0.19         5\n",
      "         738       0.00      0.00      0.00         1\n",
      "         739       0.00      0.00      0.00         1\n",
      "         740       0.00      0.00      0.00         4\n",
      "         742       0.00      0.00      0.00         1\n",
      "         743       0.00      0.00      0.00         5\n",
      "         744       0.00      0.00      0.00         1\n",
      "         745       0.00      0.00      0.00         3\n",
      "         746       0.18      0.25      0.21         8\n",
      "         747       0.00      0.00      0.00         1\n",
      "         749       0.00      0.00      0.00         1\n",
      "         750       0.00      0.00      0.00         1\n",
      "         752       0.00      0.00      0.00         1\n",
      "         753       0.00      0.00      0.00         4\n",
      "         754       0.00      0.00      0.00         1\n",
      "         755       0.00      0.00      0.00         2\n",
      "         756       0.00      0.00      0.00         6\n",
      "         758       0.00      0.00      0.00         5\n",
      "         759       0.00      0.00      0.00         4\n",
      "         760       0.00      0.00      0.00         2\n",
      "         761       0.00      0.00      0.00         2\n",
      "         762       0.00      0.00      0.00         2\n",
      "         763       0.00      0.00      0.00         2\n",
      "         764       0.00      0.00      0.00         4\n",
      "         766       0.00      0.00      0.00         2\n",
      "         767       0.00      0.00      0.00         1\n",
      "         770       0.00      0.00      0.00         1\n",
      "         771       0.00      0.00      0.00         2\n",
      "         772       0.00      0.00      0.00         1\n",
      "         773       0.00      0.00      0.00         4\n",
      "         774       0.00      0.00      0.00         2\n",
      "         775       0.00      0.00      0.00         2\n",
      "         776       0.00      0.00      0.00         0\n",
      "         777       0.00      0.00      0.00         2\n",
      "         778       0.00      0.00      0.00         1\n",
      "         779       0.00      0.00      0.00         4\n",
      "         780       0.36      0.36      0.36        11\n",
      "         781       0.00      0.00      0.00         4\n",
      "         782       0.00      0.00      0.00         2\n",
      "         784       0.00      0.00      0.00         1\n",
      "         786       0.00      0.00      0.00         1\n",
      "         787       0.00      0.00      0.00         3\n",
      "         788       0.00      0.00      0.00         1\n",
      "         789       0.00      0.00      0.00         1\n",
      "         790       0.00      0.00      0.00         1\n",
      "         791       0.00      0.00      0.00         1\n",
      "         792       1.00      0.50      0.67         4\n",
      "         793       0.00      0.00      0.00         9\n",
      "         795       0.00      0.00      0.00         3\n",
      "         796       0.00      0.00      0.00         4\n",
      "         797       0.00      0.00      0.00         4\n",
      "         798       0.00      0.00      0.00         2\n",
      "         799       0.00      0.00      0.00         3\n",
      "         800       0.00      0.00      0.00         4\n",
      "         801       0.00      0.00      0.00         1\n",
      "         802       0.00      0.00      0.00         5\n",
      "         803       0.00      0.00      0.00         1\n",
      "         804       0.00      0.00      0.00         1\n",
      "         805       0.00      0.00      0.00         1\n",
      "         806       0.00      0.00      0.00         3\n",
      "         807       0.00      0.00      0.00         2\n",
      "         808       0.17      0.12      0.14         8\n",
      "         810       0.00      0.00      0.00         2\n",
      "         811       0.00      0.00      0.00         1\n",
      "         812       0.00      0.00      0.00         3\n",
      "         814       0.00      0.00      0.00         3\n",
      "         815       0.00      0.00      0.00         7\n",
      "         816       0.00      0.00      0.00         3\n",
      "         818       0.00      0.00      0.00         2\n",
      "         819       0.00      0.00      0.00         2\n",
      "         820       0.00      0.00      0.00         1\n",
      "         821       0.00      0.00      0.00         2\n",
      "         822       0.14      0.50      0.22         4\n",
      "         823       0.00      0.00      0.00         1\n",
      "         824       0.00      0.00      0.00         2\n",
      "         826       0.00      0.00      0.00         1\n",
      "         827       0.07      0.09      0.08        11\n",
      "         828       0.00      0.00      0.00         1\n",
      "         829       0.00      0.00      0.00         2\n",
      "         830       0.00      0.00      0.00         3\n",
      "         831       0.00      0.00      0.00         2\n",
      "         832       0.00      0.00      0.00         2\n",
      "         833       0.00      0.00      0.00         3\n",
      "         834       0.00      0.00      0.00         5\n",
      "         835       0.00      0.00      0.00         3\n",
      "         836       0.00      0.00      0.00         1\n",
      "         837       0.00      0.00      0.00         1\n",
      "         839       0.00      0.00      0.00         4\n",
      "         841       0.00      0.00      0.00         1\n",
      "         842       0.00      0.00      0.00         1\n",
      "         845       0.00      0.00      0.00         1\n",
      "         846       0.00      0.00      0.00         1\n",
      "         847       0.00      0.00      0.00         1\n",
      "         848       0.40      0.50      0.44         4\n",
      "         850       0.20      0.50      0.29         2\n",
      "         851       0.00      0.00      0.00         6\n",
      "         853       0.00      0.00      0.00         2\n",
      "         855       0.00      0.00      0.00         1\n",
      "         856       0.23      0.36      0.28       109\n",
      "         857       0.00      0.00      0.00         3\n",
      "         858       0.00      0.00      0.00         2\n",
      "         859       0.00      0.00      0.00         2\n",
      "         860       0.00      0.00      0.00         1\n",
      "         861       0.00      0.00      0.00         2\n",
      "         862       0.00      0.00      0.00         3\n",
      "         863       0.00      0.00      0.00         1\n",
      "         864       0.00      0.00      0.00         5\n",
      "         865       0.00      0.00      0.00         1\n",
      "         866       0.00      0.00      0.00         2\n",
      "         867       0.00      0.00      0.00         2\n",
      "         868       0.00      0.00      0.00         2\n",
      "         869       0.00      0.00      0.00         1\n",
      "         871       0.00      0.00      0.00         2\n",
      "         873       0.00      0.00      0.00         1\n",
      "         874       0.00      0.00      0.00         3\n",
      "         875       0.00      0.00      0.00         2\n",
      "         876       0.27      0.55      0.36        58\n",
      "         877       0.00      0.00      0.00        10\n",
      "         878       0.00      0.00      0.00         6\n",
      "         880       0.00      0.00      0.00         2\n",
      "         881       0.00      0.00      0.00         1\n",
      "         884       0.00      0.00      0.00         1\n",
      "         885       0.00      0.00      0.00         2\n",
      "         886       0.00      0.00      0.00         1\n",
      "         889       0.00      0.00      0.00         3\n",
      "         891       0.00      0.00      0.00         4\n",
      "         892       0.00      0.00      0.00         2\n",
      "         893       0.00      0.00      0.00         2\n",
      "         894       0.00      0.00      0.00         3\n",
      "         895       0.00      0.00      0.00         3\n",
      "         896       0.00      0.00      0.00         9\n",
      "         897       0.00      0.00      0.00         4\n",
      "         898       0.00      0.00      0.00         4\n",
      "         899       0.00      0.00      0.00         1\n",
      "         900       0.00      0.00      0.00         3\n",
      "         902       0.00      0.00      0.00         4\n",
      "         903       0.00      0.00      0.00         1\n",
      "         904       0.00      0.00      0.00         2\n",
      "         905       0.00      0.00      0.00         5\n",
      "         906       0.00      0.00      0.00         7\n",
      "         907       0.00      0.00      0.00         5\n",
      "         908       0.00      0.00      0.00         1\n",
      "         909       0.00      0.00      0.00         1\n",
      "         910       0.00      0.00      0.00         3\n",
      "         911       0.00      0.00      0.00         8\n",
      "         913       0.00      0.00      0.00         2\n",
      "         914       0.00      0.00      0.00         2\n",
      "         915       0.00      0.00      0.00         5\n",
      "         916       0.00      0.00      0.00         2\n",
      "         918       0.00      0.00      0.00         2\n",
      "         920       0.22      0.17      0.19        12\n",
      "         921       0.00      0.00      0.00         2\n",
      "         922       0.00      0.00      0.00         1\n",
      "         923       0.00      0.00      0.00         1\n",
      "         925       0.00      0.00      0.00         2\n",
      "         926       0.00      0.00      0.00         3\n",
      "         927       0.00      0.00      0.00         0\n",
      "         928       0.00      0.00      0.00         3\n",
      "         929       0.00      0.00      0.00         3\n",
      "         930       0.09      0.33      0.14         6\n",
      "         932       0.00      0.00      0.00         1\n",
      "         934       0.00      0.00      0.00         6\n",
      "         937       0.00      0.00      0.00         1\n",
      "         938       0.00      0.00      0.00         1\n",
      "         939       0.00      0.00      0.00         3\n",
      "         940       0.00      0.00      0.00         2\n",
      "         942       0.00      0.00      0.00         3\n",
      "         943       0.00      0.00      0.00         7\n",
      "         944       0.00      0.00      0.00         2\n",
      "         945       0.00      0.00      0.00         3\n",
      "         946       0.07      0.12      0.09         8\n",
      "         947       0.00      0.00      0.00         1\n",
      "         948       0.00      0.00      0.00         5\n",
      "         949       0.00      0.00      0.00         6\n",
      "         950       0.00      0.00      0.00         2\n",
      "         951       0.14      0.22      0.17         9\n",
      "         952       0.23      0.70      0.34        10\n",
      "         953       0.00      0.00      0.00         2\n",
      "         954       0.00      0.00      0.00         1\n",
      "         956       0.00      0.00      0.00         1\n",
      "         957       0.00      0.00      0.00         0\n",
      "         958       0.00      0.00      0.00         3\n",
      "         959       0.00      0.00      0.00         3\n",
      "         961       0.00      0.00      0.00         4\n",
      "         962       0.00      0.00      0.00         3\n",
      "         963       0.00      0.00      0.00         5\n",
      "         964       0.00      0.00      0.00         1\n",
      "         965       0.00      0.00      0.00         6\n",
      "         966       0.00      0.00      0.00         2\n",
      "         967       0.00      0.00      0.00         5\n",
      "         968       0.00      0.00      0.00         1\n",
      "         970       0.00      0.00      0.00         2\n",
      "         971       0.70      0.58      0.64        12\n",
      "         972       0.00      0.00      0.00         2\n",
      "         974       0.00      0.00      0.00         8\n",
      "         976       0.00      0.00      0.00         4\n",
      "         977       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         4\n",
      "         979       0.00      0.00      0.00         4\n",
      "         980       0.00      0.00      0.00         1\n",
      "         981       0.00      0.00      0.00         1\n",
      "         982       0.00      0.00      0.00         2\n",
      "         983       0.00      0.00      0.00         2\n",
      "         984       0.00      0.00      0.00         1\n",
      "         985       0.00      0.00      0.00         2\n",
      "         986       0.00      0.00      0.00         2\n",
      "         988       0.00      0.00      0.00         4\n",
      "         989       0.00      0.00      0.00         1\n",
      "         990       0.00      0.00      0.00         1\n",
      "         991       0.00      0.00      0.00         4\n",
      "         992       0.00      0.00      0.00         1\n",
      "         993       0.00      0.00      0.00         1\n",
      "         994       0.22      0.62      0.32        16\n",
      "         995       0.00      0.00      0.00         4\n",
      "         996       0.00      0.00      0.00         1\n",
      "         997       0.00      0.00      0.00         5\n",
      "         998       0.00      0.00      0.00         2\n",
      "         999       0.00      0.00      0.00         3\n",
      "        1000       0.00      0.00      0.00         2\n",
      "        1001       0.14      0.33      0.20        12\n",
      "        1002       0.00      0.00      0.00         1\n",
      "        1003       0.00      0.00      0.00         1\n",
      "        1004       0.00      0.00      0.00         1\n",
      "        1005       0.00      0.00      0.00         3\n",
      "        1006       0.00      0.00      0.00         1\n",
      "        1007       0.00      0.00      0.00         1\n",
      "        1008       0.08      0.22      0.11         9\n",
      "        1009       0.00      0.00      0.00         4\n",
      "        1010       0.00      0.00      0.00         4\n",
      "        1011       0.00      0.00      0.00         3\n",
      "        1012       0.00      0.00      0.00         1\n",
      "        1013       0.00      0.00      0.00         3\n",
      "        1015       0.00      0.00      0.00         1\n",
      "        1016       0.00      0.00      0.00         3\n",
      "        1017       0.00      0.00      0.00         1\n",
      "        1018       0.00      0.00      0.00         7\n",
      "        1019       0.00      0.00      0.00         3\n",
      "        1020       0.00      0.00      0.00         2\n",
      "        1021       0.00      0.00      0.00         3\n",
      "        1022       0.00      0.00      0.00         4\n",
      "        1023       0.00      0.00      0.00         2\n",
      "        1024       1.00      0.40      0.57         5\n",
      "        1025       0.00      0.00      0.00         1\n",
      "        1026       0.00      0.00      0.00         5\n",
      "        1027       0.00      0.00      0.00         1\n",
      "        1028       0.00      0.00      0.00         1\n",
      "        1029       0.00      0.00      0.00         1\n",
      "        1030       0.00      0.00      0.00         1\n",
      "        1031       0.00      0.00      0.00         4\n",
      "        1032       0.00      0.00      0.00         2\n",
      "        1033       0.00      0.00      0.00         1\n",
      "        1034       0.00      0.00      0.00         6\n",
      "        1035       0.00      0.00      0.00         2\n",
      "        1036       0.00      0.00      0.00         1\n",
      "        1038       0.00      0.00      0.00         2\n",
      "        1039       0.00      0.00      0.00         3\n",
      "        1040       0.00      0.00      0.00         2\n",
      "        1041       0.00      0.00      0.00         2\n",
      "        1043       0.00      0.00      0.00         2\n",
      "        1044       0.00      0.00      0.00         3\n",
      "        1045       0.00      0.00      0.00         1\n",
      "        1046       0.00      0.00      0.00         2\n",
      "        1047       0.00      0.00      0.00         2\n",
      "        1048       0.00      0.00      0.00         3\n",
      "        1049       0.00      0.00      0.00         1\n",
      "        1051       0.00      0.00      0.00         2\n",
      "        1052       0.00      0.00      0.00         1\n",
      "        1053       0.00      0.00      0.00         1\n",
      "        1054       0.00      0.00      0.00         2\n",
      "        1055       0.00      0.00      0.00         3\n",
      "        1056       0.00      0.00      0.00         4\n",
      "        1057       0.00      0.00      0.00         3\n",
      "        1058       0.00      0.00      0.00         2\n",
      "        1059       0.00      0.00      0.00         2\n",
      "        1060       0.00      0.00      0.00         1\n",
      "        1061       0.00      0.00      0.00         3\n",
      "        1062       0.00      0.00      0.00         2\n",
      "        1063       0.00      0.00      0.00         1\n",
      "        1064       0.00      0.00      0.00         2\n",
      "        1065       0.00      0.00      0.00         1\n",
      "        1067       0.00      0.00      0.00         3\n",
      "        1068       0.00      0.00      0.00         3\n",
      "        1069       0.00      0.00      0.00         5\n",
      "        1070       0.00      0.00      0.00         2\n",
      "        1071       0.00      0.00      0.00         1\n",
      "        1072       0.00      0.00      0.00         4\n",
      "        1073       0.00      0.00      0.00         1\n",
      "        1074       0.00      0.00      0.00         4\n",
      "        1075       0.00      0.00      0.00         3\n",
      "        1076       0.00      0.00      0.00         2\n",
      "        1077       0.00      0.00      0.00         1\n",
      "        1078       0.23      0.90      0.36        10\n",
      "        1079       0.00      0.00      0.00         6\n",
      "        1080       0.00      0.00      0.00         2\n",
      "        1081       0.00      0.00      0.00         1\n",
      "        1082       0.00      0.00      0.00         2\n",
      "        1083       0.00      0.00      0.00         3\n",
      "        1084       0.00      0.00      0.00         1\n",
      "        1086       0.18      0.60      0.28        30\n",
      "        1087       0.00      0.00      0.00         6\n",
      "        1088       0.00      0.00      0.00         7\n",
      "        1089       0.00      0.00      0.00         2\n",
      "        1091       0.00      0.00      0.00         2\n",
      "        1092       0.00      0.00      0.00         3\n",
      "        1093       0.00      0.00      0.00         9\n",
      "        1094       0.33      0.85      0.48       659\n",
      "        1095       0.00      0.00      0.00         1\n",
      "        1096       0.00      0.00      0.00         2\n",
      "        1097       0.00      0.00      0.00         6\n",
      "        1098       0.00      0.00      0.00         1\n",
      "        1099       0.00      0.00      0.00         2\n",
      "        1100       0.00      0.00      0.00         4\n",
      "        1102       0.00      0.00      0.00         1\n",
      "        1104       0.00      0.00      0.00         1\n",
      "        1105       0.00      0.00      0.00         1\n",
      "        1106       0.00      0.00      0.00         2\n",
      "        1107       0.00      0.00      0.00         2\n",
      "        1108       0.00      0.00      0.00         3\n",
      "        1109       0.00      0.00      0.00         2\n",
      "        1110       0.00      0.00      0.00         1\n",
      "        1111       0.00      0.00      0.00         1\n",
      "        1112       0.00      0.00      0.00         2\n",
      "        1113       0.00      0.00      0.00         2\n",
      "        1114       0.00      0.00      0.00         3\n",
      "        1115       0.00      0.00      0.00         6\n",
      "        1116       0.00      0.00      0.00         1\n",
      "        1117       0.00      0.00      0.00         3\n",
      "        1118       0.00      0.00      0.00         7\n",
      "        1120       0.00      0.00      0.00         3\n",
      "        1122       0.00      0.00      0.00         1\n",
      "        1123       0.00      0.00      0.00         3\n",
      "        1124       0.38      1.00      0.55         3\n",
      "        1125       0.25      0.17      0.20         6\n",
      "        1127       0.00      0.00      0.00         6\n",
      "        1128       0.00      0.00      0.00         2\n",
      "        1129       0.00      0.00      0.00         3\n",
      "        1130       0.00      0.00      0.00         2\n",
      "        1132       0.00      0.00      0.00         2\n",
      "        1133       0.00      0.00      0.00         2\n",
      "        1135       0.00      0.00      0.00         3\n",
      "        1136       0.00      0.00      0.00         5\n",
      "        1137       0.21      0.78      0.33         9\n",
      "        1138       0.00      0.00      0.00         2\n",
      "        1139       0.00      0.00      0.00         1\n",
      "        1140       0.00      0.00      0.00         3\n",
      "        1143       0.00      0.00      0.00         6\n",
      "        1144       0.00      0.00      0.00         2\n",
      "        1145       0.00      0.00      0.00         3\n",
      "        1146       0.00      0.00      0.00         6\n",
      "        1147       0.00      0.00      0.00         2\n",
      "        1148       0.00      0.00      0.00         1\n",
      "        1149       0.00      0.00      0.00         7\n",
      "        1150       0.00      0.00      0.00         5\n",
      "        1152       0.00      0.00      0.00         3\n",
      "        1153       0.00      0.00      0.00         1\n",
      "        1154       0.00      0.00      0.00         3\n",
      "        1155       0.00      0.00      0.00         3\n",
      "        1156       0.00      0.00      0.00         1\n",
      "        1157       0.00      0.00      0.00         2\n",
      "        1158       0.00      0.00      0.00         2\n",
      "        1160       0.00      0.00      0.00         1\n",
      "        1161       0.00      0.00      0.00         2\n",
      "        1162       0.00      0.00      0.00         1\n",
      "        1165       0.00      0.00      0.00         6\n",
      "        1166       0.00      0.00      0.00         2\n",
      "        1167       0.00      0.00      0.00         5\n",
      "        1169       0.00      0.00      0.00         4\n",
      "        1170       0.00      0.00      0.00         1\n",
      "        1171       0.00      0.00      0.00         1\n",
      "        1172       0.00      0.00      0.00         2\n",
      "        1173       0.00      0.00      0.00         1\n",
      "        1174       0.00      0.00      0.00         2\n",
      "        1176       0.00      0.00      0.00         3\n",
      "        1177       0.09      0.14      0.11         7\n",
      "        1180       0.12      0.29      0.17         7\n",
      "        1182       0.00      0.00      0.00         2\n",
      "        1184       0.00      0.00      0.00         1\n",
      "        1185       0.00      0.00      0.00         1\n",
      "        1186       0.00      0.00      0.00         4\n",
      "        1187       0.00      0.00      0.00         1\n",
      "        1188       0.00      0.00      0.00         2\n",
      "        1189       0.07      0.60      0.12        10\n",
      "        1190       0.00      0.00      0.00         3\n",
      "        1191       0.00      0.00      0.00         2\n",
      "        1192       0.50      0.43      0.46         7\n",
      "        1193       0.00      0.00      0.00         5\n",
      "        1194       0.25      0.20      0.22         5\n",
      "        1195       0.00      0.00      0.00         6\n",
      "        1196       0.00      0.00      0.00         2\n",
      "        1197       0.00      0.00      0.00         2\n",
      "        1198       0.00      0.00      0.00         1\n",
      "        1200       0.08      0.22      0.12         9\n",
      "        1201       0.00      0.00      0.00         4\n",
      "        1202       0.00      0.00      0.00         4\n",
      "        1205       0.00      0.00      0.00         3\n",
      "        1209       0.00      0.00      0.00         1\n",
      "        1210       0.00      0.00      0.00         1\n",
      "        1211       0.00      0.00      0.00         0\n",
      "        1212       0.00      0.00      0.00         1\n",
      "        1213       0.00      0.00      0.00         1\n",
      "        1214       0.00      0.00      0.00         3\n",
      "        1215       0.00      0.00      0.00         2\n",
      "        1216       0.00      0.00      0.00         2\n",
      "        1217       0.00      0.00      0.00         1\n",
      "        1218       0.00      0.00      0.00         3\n",
      "        1219       0.00      0.00      0.00         1\n",
      "        1220       0.00      0.00      0.00         1\n",
      "        1221       0.00      0.00      0.00        11\n",
      "        1222       0.00      0.00      0.00         2\n",
      "        1223       0.00      0.00      0.00         1\n",
      "        1224       0.00      0.00      0.00         1\n",
      "        1226       0.00      0.00      0.00         1\n",
      "        1227       0.00      0.00      0.00         3\n",
      "        1228       0.20      0.40      0.27         5\n",
      "        1229       0.00      0.00      0.00         2\n",
      "        1230       0.00      0.00      0.00         1\n",
      "        1231       0.00      0.00      0.00         1\n",
      "        1232       0.00      0.00      0.00         1\n",
      "        1233       0.00      0.00      0.00         2\n",
      "        1234       0.00      0.00      0.00         1\n",
      "        1236       0.00      0.00      0.00         2\n",
      "        1237       0.00      0.00      0.00         6\n",
      "        1238       0.00      0.00      0.00         1\n",
      "        1239       0.00      0.00      0.00         5\n",
      "        1240       0.33      0.20      0.25         5\n",
      "        1242       0.00      0.00      0.00         1\n",
      "        1243       0.00      0.00      0.00         5\n",
      "        1244       0.00      0.00      0.00         2\n",
      "        1245       0.00      0.00      0.00         1\n",
      "        1246       0.00      0.00      0.00         2\n",
      "        1247       0.00      0.00      0.00         1\n",
      "        1248       0.00      0.00      0.00         2\n",
      "        1249       0.00      0.00      0.00         7\n",
      "        1251       0.00      0.00      0.00         1\n",
      "        1252       0.00      0.00      0.00         4\n",
      "        1253       0.00      0.00      0.00         2\n",
      "        1254       0.00      0.00      0.00         2\n",
      "        1255       0.00      0.00      0.00         2\n",
      "        1256       0.00      0.00      0.00         1\n",
      "        1257       0.00      0.00      0.00         2\n",
      "        1258       0.00      0.00      0.00         1\n",
      "        1259       0.00      0.00      0.00         2\n",
      "        1260       0.00      0.00      0.00         4\n",
      "        1262       0.00      0.00      0.00         2\n",
      "        1264       0.00      0.00      0.00         3\n",
      "        1265       0.05      0.20      0.08         5\n",
      "        1266       0.00      0.00      0.00         1\n",
      "        1267       0.00      0.00      0.00         2\n",
      "        1269       0.00      0.00      0.00         5\n",
      "        1272       0.00      0.00      0.00         2\n",
      "        1275       0.00      0.00      0.00         1\n",
      "        1276       0.00      0.00      0.00         4\n",
      "        1277       0.00      0.00      0.00         6\n",
      "        1278       0.00      0.00      0.00         1\n",
      "        1279       0.00      0.00      0.00         2\n",
      "        1280       0.00      0.00      0.00         1\n",
      "        1281       0.00      0.00      0.00         3\n",
      "        1282       0.00      0.00      0.00         3\n",
      "        1283       0.00      0.00      0.00         1\n",
      "        1284       0.00      0.00      0.00         1\n",
      "        1285       0.00      0.00      0.00         2\n",
      "        1286       0.00      0.00      0.00         1\n",
      "        1287       0.00      0.00      0.00         6\n",
      "        1288       0.00      0.00      0.00         2\n",
      "        1289       0.00      0.00      0.00         2\n",
      "        1290       0.00      0.00      0.00         3\n",
      "        1291       0.00      0.00      0.00         1\n",
      "        1292       0.00      0.00      0.00         5\n",
      "        1293       0.33      0.50      0.40        10\n",
      "        1294       0.00      0.00      0.00         1\n",
      "        1295       0.00      0.00      0.00         5\n",
      "        1296       0.00      0.00      0.00         1\n",
      "        1297       0.00      0.00      0.00         3\n",
      "        1298       0.23      0.36      0.28        14\n",
      "        1299       0.00      0.00      0.00         2\n",
      "        1300       0.00      0.00      0.00         3\n",
      "        1301       0.00      0.00      0.00         1\n",
      "        1302       0.00      0.00      0.00         1\n",
      "        1303       0.00      0.00      0.00         1\n",
      "        1306       0.00      0.00      0.00         1\n",
      "        1308       0.00      0.00      0.00         4\n",
      "        1309       0.00      0.00      0.00         3\n",
      "        1310       0.00      0.00      0.00         2\n",
      "        1311       0.00      0.00      0.00         3\n",
      "        1312       0.00      0.00      0.00         1\n",
      "        1313       0.00      0.00      0.00         4\n",
      "        1314       0.00      0.00      0.00         5\n",
      "        1315       0.00      0.00      0.00         5\n",
      "        1316       0.00      0.00      0.00         2\n",
      "        1318       0.00      0.00      0.00         1\n",
      "        1319       0.00      0.00      0.00         2\n",
      "        1320       0.00      0.00      0.00         1\n",
      "        1321       0.00      0.00      0.00         1\n",
      "        1322       0.00      0.00      0.00         2\n",
      "        1323       0.00      0.00      0.00         2\n",
      "        1324       0.00      0.00      0.00         1\n",
      "        1326       0.09      0.75      0.16        12\n",
      "        1327       0.00      0.00      0.00         4\n",
      "        1328       0.00      0.00      0.00         4\n",
      "        1329       0.00      0.00      0.00         1\n",
      "        1331       0.00      0.00      0.00         1\n",
      "        1332       1.00      0.33      0.50         3\n",
      "        1333       0.00      0.00      0.00         2\n",
      "        1334       0.00      0.00      0.00         1\n",
      "        1335       0.00      0.00      0.00         1\n",
      "        1336       0.00      0.00      0.00         3\n",
      "        1337       0.00      0.00      0.00         2\n",
      "        1338       0.00      0.00      0.00         1\n",
      "        1339       0.00      0.00      0.00         1\n",
      "        1340       0.00      0.00      0.00         2\n",
      "        1341       0.00      0.00      0.00         4\n",
      "        1342       0.00      0.00      0.00         3\n",
      "        1343       0.00      0.00      0.00         2\n",
      "        1344       0.00      0.00      0.00         2\n",
      "        1345       0.00      0.00      0.00         1\n",
      "        1346       0.00      0.00      0.00         3\n",
      "        1347       0.00      0.00      0.00         1\n",
      "        1348       0.00      0.00      0.00         3\n",
      "        1349       0.00      0.00      0.00         3\n",
      "        1350       0.00      0.00      0.00         1\n",
      "        1352       0.00      0.00      0.00         3\n",
      "        1353       0.00      0.00      0.00         4\n",
      "        1354       0.00      0.00      0.00         4\n",
      "        1355       0.00      0.00      0.00         3\n",
      "        1356       0.00      0.00      0.00         4\n",
      "        1357       0.00      0.00      0.00         1\n",
      "        1358       0.00      0.00      0.00         1\n",
      "        1359       0.00      0.00      0.00         1\n",
      "        1360       0.00      0.00      0.00         2\n",
      "        1361       0.00      0.00      0.00         2\n",
      "        1362       0.00      0.00      0.00         2\n",
      "        1364       0.00      0.00      0.00         7\n",
      "        1365       0.00      0.00      0.00         2\n",
      "        1367       0.00      0.00      0.00         2\n",
      "        1368       0.00      0.00      0.00         2\n",
      "        1369       0.00      0.00      0.00         1\n",
      "        1370       0.10      0.33      0.15         6\n",
      "        1371       0.09      0.20      0.13         5\n",
      "        1373       0.00      0.00      0.00         6\n",
      "        1374       0.00      0.00      0.00         1\n",
      "        1375       0.00      0.00      0.00         1\n",
      "        1376       0.00      0.00      0.00         1\n",
      "        1377       0.00      0.00      0.00         1\n",
      "        1379       0.00      0.00      0.00         1\n",
      "        1380       0.00      0.00      0.00         2\n",
      "        1381       0.00      0.00      0.00         6\n",
      "        1382       0.00      0.00      0.00         1\n",
      "        1383       0.00      0.00      0.00        11\n",
      "        1384       0.00      0.00      0.00         2\n",
      "        1385       0.00      0.00      0.00         1\n",
      "        1386       0.00      0.00      0.00         1\n",
      "        1387       0.00      0.00      0.00         3\n",
      "        1388       0.00      0.00      0.00         2\n",
      "        1389       0.00      0.00      0.00         1\n",
      "        1390       0.00      0.00      0.00         2\n",
      "        1391       0.00      0.00      0.00         5\n",
      "        1392       0.00      0.00      0.00         5\n",
      "        1394       0.14      0.12      0.13         8\n",
      "        1396       0.00      0.00      0.00         1\n",
      "        1397       0.00      0.00      0.00         3\n",
      "        1398       0.00      0.00      0.00         3\n",
      "        1399       0.00      0.00      0.00         2\n",
      "        1401       0.00      0.00      0.00         4\n",
      "        1402       0.00      0.00      0.00         1\n",
      "        1403       0.00      0.00      0.00         1\n",
      "        1404       0.00      0.00      0.00         1\n",
      "        1405       0.00      0.00      0.00         2\n",
      "        1406       0.09      0.71      0.16         7\n",
      "        1407       0.00      0.00      0.00         2\n",
      "        1408       0.00      0.00      0.00         1\n",
      "        1409       0.00      0.00      0.00         4\n",
      "        1410       0.00      0.00      0.00         2\n",
      "        1411       0.00      0.00      0.00         2\n",
      "        1412       0.00      0.00      0.00         1\n",
      "        1413       0.00      0.00      0.00         4\n",
      "        1414       0.00      0.00      0.00         1\n",
      "        1415       0.00      0.00      0.00         6\n",
      "        1416       0.00      0.00      0.00         1\n",
      "        1417       0.00      0.00      0.00         2\n",
      "        1418       0.00      0.00      0.00         2\n",
      "        1420       0.00      0.00      0.00         1\n",
      "        1421       0.00      0.00      0.00         3\n",
      "        1422       0.00      0.00      0.00         3\n",
      "        1423       0.00      0.00      0.00         6\n",
      "        1424       0.00      0.00      0.00         1\n",
      "        1425       0.00      0.00      0.00         1\n",
      "        1426       0.00      0.00      0.00         1\n",
      "        1427       0.00      0.00      0.00         2\n",
      "        1429       0.00      0.00      0.00         2\n",
      "        1430       0.00      0.00      0.00         1\n",
      "        1431       0.00      0.00      0.00         5\n",
      "        1432       0.00      0.00      0.00         2\n",
      "        1433       0.00      0.00      0.00         3\n",
      "        1435       0.00      0.00      0.00         3\n",
      "        1436       0.00      0.00      0.00         5\n",
      "        1437       0.00      0.00      0.00         1\n",
      "        1438       0.00      0.00      0.00         2\n",
      "        1439       0.00      0.00      0.00         2\n",
      "        1440       0.00      0.00      0.00         3\n",
      "        1441       0.00      0.00      0.00         1\n",
      "        1442       0.00      0.00      0.00         1\n",
      "        1443       0.00      0.00      0.00         3\n",
      "        1445       0.00      0.00      0.00         1\n",
      "        1448       0.00      0.00      0.00         1\n",
      "        1449       0.00      0.00      0.00         2\n",
      "        1450       0.00      0.00      0.00         2\n",
      "        1451       0.14      0.36      0.20        14\n",
      "        1452       0.00      0.00      0.00         5\n",
      "        1453       0.00      0.00      0.00         1\n",
      "        1454       0.00      0.00      0.00         3\n",
      "        1455       0.00      0.00      0.00         3\n",
      "        1456       0.00      0.00      0.00         1\n",
      "        1457       0.00      0.00      0.00         3\n",
      "        1458       0.00      0.00      0.00         5\n",
      "        1459       0.00      0.00      0.00         3\n",
      "        1460       0.00      0.00      0.00         5\n",
      "        1461       0.00      0.00      0.00         3\n",
      "        1462       0.00      0.00      0.00         3\n",
      "        1463       0.00      0.00      0.00         1\n",
      "        1465       0.00      0.00      0.00         3\n",
      "        1466       0.00      0.00      0.00         1\n",
      "        1467       0.00      0.00      0.00         2\n",
      "        1468       0.00      0.00      0.00         2\n",
      "        1469       0.00      0.00      0.00         7\n",
      "        1470       0.00      0.00      0.00         1\n",
      "        1472       0.00      0.00      0.00         1\n",
      "        1474       0.10      0.12      0.11         8\n",
      "        1477       0.00      0.00      0.00         9\n",
      "        1478       0.00      0.00      0.00         2\n",
      "        1479       0.00      0.00      0.00         1\n",
      "        1480       0.00      0.00      0.00         2\n",
      "        1481       0.00      0.00      0.00        10\n",
      "        1482       0.00      0.00      0.00         1\n",
      "        1483       0.00      0.00      0.00         1\n",
      "        1484       0.00      0.00      0.00        12\n",
      "        1485       0.00      0.00      0.00         2\n",
      "        1486       0.00      0.00      0.00         2\n",
      "        1487       0.00      0.00      0.00         1\n",
      "        1488       0.00      0.00      0.00         1\n",
      "        1489       0.00      0.00      0.00         2\n",
      "        1490       0.00      0.00      0.00         1\n",
      "        1491       0.00      0.00      0.00         2\n",
      "        1492       0.00      0.00      0.00         3\n",
      "        1493       0.00      0.00      0.00         5\n",
      "        1494       0.00      0.00      0.00         2\n",
      "        1495       0.00      0.00      0.00         2\n",
      "        1496       0.00      0.00      0.00         1\n",
      "        1497       0.00      0.00      0.00         1\n",
      "        1498       0.00      0.00      0.00         1\n",
      "        1499       0.00      0.00      0.00         2\n",
      "        1500       0.11      0.25      0.15         4\n",
      "        1501       0.00      0.00      0.00         2\n",
      "        1502       0.00      0.00      0.00         1\n",
      "        1503       0.00      0.00      0.00         3\n",
      "        1504       0.00      0.00      0.00         1\n",
      "        1506       0.00      0.00      0.00         1\n",
      "        1507       0.13      0.54      0.21        13\n",
      "        1508       0.00      0.00      0.00         4\n",
      "        1510       0.00      0.00      0.00         1\n",
      "        1511       0.00      0.00      0.00         1\n",
      "        1512       0.00      0.00      0.00         3\n",
      "        1513       0.00      0.00      0.00         1\n",
      "        1514       0.00      0.00      0.00         2\n",
      "        1515       0.00      0.00      0.00         2\n",
      "        1516       0.00      0.00      0.00         1\n",
      "        1517       0.00      0.00      0.00         1\n",
      "        1519       0.00      0.00      0.00         4\n",
      "        1520       0.00      0.00      0.00         4\n",
      "        1521       0.00      0.00      0.00         1\n",
      "        1522       0.00      0.00      0.00         2\n",
      "        1523       0.00      0.00      0.00         2\n",
      "        1524       0.00      0.00      0.00         2\n",
      "        1525       0.00      0.00      0.00         2\n",
      "        1526       0.00      0.00      0.00         5\n",
      "        1527       0.00      0.00      0.00         2\n",
      "        1528       0.09      0.25      0.13         4\n",
      "        1529       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         5\n",
      "        1531       0.00      0.00      0.00         3\n",
      "        1532       0.00      0.00      0.00         6\n",
      "        1534       0.00      0.00      0.00         1\n",
      "        1535       0.00      0.00      0.00         3\n",
      "        1536       0.00      0.00      0.00         1\n",
      "        1537       0.06      0.86      0.11         7\n",
      "        1538       0.00      0.00      0.00         1\n",
      "        1539       0.00      0.00      0.00         2\n",
      "        1540       0.00      0.00      0.00         4\n",
      "        1541       0.00      0.00      0.00         2\n",
      "        1542       0.00      0.00      0.00         3\n",
      "        1543       0.00      0.00      0.00         1\n",
      "        1544       0.00      0.00      0.00         4\n",
      "        1545       0.00      0.00      0.00         1\n",
      "        1546       0.00      0.00      0.00         2\n",
      "        1547       0.00      0.00      0.00         0\n",
      "        1551       0.00      0.00      0.00         2\n",
      "        1552       0.00      0.00      0.00         2\n",
      "        1553       0.00      0.00      0.00         2\n",
      "        1554       0.00      0.00      0.00         1\n",
      "        1555       0.00      0.00      0.00         1\n",
      "        1556       0.00      0.00      0.00         3\n",
      "        1557       0.00      0.00      0.00         2\n",
      "        1558       0.00      0.00      0.00         1\n",
      "        1559       0.00      0.00      0.00         5\n",
      "        1560       0.00      0.00      0.00         1\n",
      "        1562       0.00      0.00      0.00         4\n",
      "        1563       0.00      0.00      0.00         2\n",
      "        1565       0.00      0.00      0.00         1\n",
      "        1566       0.00      0.00      0.00         1\n",
      "        1567       0.00      0.00      0.00         2\n",
      "        1569       0.00      0.00      0.00         1\n",
      "        1570       0.00      0.00      0.00         6\n",
      "        1571       0.00      0.00      0.00         2\n",
      "        1572       0.08      0.09      0.09        22\n",
      "        1573       0.00      0.00      0.00         6\n",
      "        1574       0.15      0.33      0.21        12\n",
      "        1575       0.00      0.00      0.00         3\n",
      "        1576       0.00      0.00      0.00         1\n",
      "        1577       0.14      0.14      0.14         7\n",
      "        1578       0.00      0.00      0.00         1\n",
      "        1579       0.00      0.00      0.00        10\n",
      "        1580       0.00      0.00      0.00         2\n",
      "        1581       0.00      0.00      0.00         3\n",
      "        1583       0.00      0.00      0.00         2\n",
      "        1584       0.00      0.00      0.00         1\n",
      "        1585       0.00      0.00      0.00         4\n",
      "        1586       0.00      0.00      0.00         3\n",
      "        1587       0.00      0.00      0.00         3\n",
      "        1588       0.00      0.00      0.00         2\n",
      "        1589       0.00      0.00      0.00         3\n",
      "        1590       0.00      0.00      0.00         8\n",
      "        1591       0.00      0.00      0.00         2\n",
      "        1592       0.00      0.00      0.00         3\n",
      "        1593       0.00      0.00      0.00         5\n",
      "        1594       0.00      0.00      0.00         1\n",
      "        1595       0.00      0.00      0.00         5\n",
      "        1596       0.00      0.00      0.00         1\n",
      "        1597       0.03      0.33      0.06         3\n",
      "        1598       0.00      0.00      0.00         1\n",
      "        1600       0.00      0.00      0.00         3\n",
      "        1601       0.00      0.00      0.00         1\n",
      "        1602       0.00      0.00      0.00         1\n",
      "        1603       0.00      0.00      0.00         3\n",
      "        1604       0.00      0.00      0.00         2\n",
      "        1605       0.12      0.50      0.19         4\n",
      "        1606       0.00      0.00      0.00         2\n",
      "        1607       0.00      0.00      0.00         7\n",
      "        1608       0.00      0.00      0.00         1\n",
      "        1609       0.00      0.00      0.00         2\n",
      "        1611       0.00      0.00      0.00         1\n",
      "        1612       0.00      0.00      0.00         4\n",
      "        1613       0.00      0.00      0.00         1\n",
      "        1614       0.00      0.00      0.00         3\n",
      "        1615       0.00      0.00      0.00         2\n",
      "        1616       0.00      0.00      0.00         5\n",
      "        1617       0.00      0.00      0.00         1\n",
      "        1618       0.00      0.00      0.00         2\n",
      "        1620       0.00      0.00      0.00         4\n",
      "        1621       0.09      0.33      0.15        18\n",
      "        1622       0.00      0.00      0.00         3\n",
      "        1623       0.00      0.00      0.00         2\n",
      "        1624       0.00      0.00      0.00         1\n",
      "        1625       0.00      0.00      0.00         2\n",
      "        1627       0.00      0.00      0.00         2\n",
      "        1628       0.00      0.00      0.00         4\n",
      "        1629       0.00      0.00      0.00         7\n",
      "        1630       0.00      0.00      0.00         2\n",
      "        1631       0.00      0.00      0.00         2\n",
      "        1632       0.00      0.00      0.00         1\n",
      "        1633       0.00      0.00      0.00         4\n",
      "        1634       0.00      0.00      0.00        10\n",
      "        1635       0.00      0.00      0.00         1\n",
      "        1636       0.00      0.00      0.00         2\n",
      "        1637       0.00      0.00      0.00         1\n",
      "        1638       0.00      0.00      0.00         1\n",
      "        1640       0.00      0.00      0.00         5\n",
      "        1641       0.07      0.50      0.13         8\n",
      "        1642       0.00      0.00      0.00         1\n",
      "        1643       0.00      0.00      0.00         3\n",
      "        1644       0.00      0.00      0.00         1\n",
      "        1645       0.00      0.00      0.00         4\n",
      "        1646       0.00      0.00      0.00         2\n",
      "        1647       0.00      0.00      0.00         1\n",
      "        1648       0.00      0.00      0.00         1\n",
      "        1649       0.00      0.00      0.00         2\n",
      "        1651       0.00      0.00      0.00         1\n",
      "        1652       0.00      0.00      0.00         4\n",
      "        1654       0.00      0.00      0.00         3\n",
      "        1655       0.00      0.00      0.00         2\n",
      "        1656       0.00      0.00      0.00         3\n",
      "        1657       0.00      0.00      0.00         1\n",
      "        1658       0.00      0.00      0.00         1\n",
      "        1659       0.00      0.00      0.00         1\n",
      "        1660       0.00      0.00      0.00         2\n",
      "        1661       0.20      0.17      0.18         6\n",
      "        1662       0.00      0.00      0.00         8\n",
      "        1666       0.00      0.00      0.00         2\n",
      "        1667       0.00      0.00      0.00         9\n",
      "        1668       0.00      0.00      0.00         1\n",
      "        1669       0.21      0.67      0.32         9\n",
      "        1670       0.29      0.33      0.31         6\n",
      "        1671       0.00      0.00      0.00         4\n",
      "        1673       0.00      0.00      0.00         1\n",
      "        1674       0.00      0.00      0.00         4\n",
      "        1675       0.00      0.00      0.00         2\n",
      "        1676       0.12      0.50      0.19        12\n",
      "        1677       0.33      0.67      0.44         3\n",
      "        1678       0.00      0.00      0.00         1\n",
      "        1679       0.00      0.00      0.00         1\n",
      "        1680       0.00      0.00      0.00         1\n",
      "        1681       1.00      0.07      0.12        15\n",
      "        1682       0.00      0.00      0.00         2\n",
      "        1683       0.00      0.00      0.00         1\n",
      "        1684       0.00      0.00      0.00         2\n",
      "        1685       0.00      0.00      0.00         4\n",
      "        1686       0.00      0.00      0.00         4\n",
      "        1687       0.00      0.00      0.00         1\n",
      "        1689       0.14      0.22      0.17         9\n",
      "        1691       0.00      0.00      0.00         1\n",
      "        1692       0.00      0.00      0.00         1\n",
      "        1693       0.00      0.00      0.00         1\n",
      "        1694       0.00      0.00      0.00         1\n",
      "        1695       0.00      0.00      0.00         2\n",
      "        1696       0.00      0.00      0.00         1\n",
      "        1697       0.00      0.00      0.00         1\n",
      "        1698       0.24      0.64      0.35        14\n",
      "        1699       0.00      0.00      0.00         1\n",
      "        1700       0.00      0.00      0.00         2\n",
      "        1701       0.50      0.43      0.46         7\n",
      "        1702       0.00      0.00      0.00         4\n",
      "        1703       0.00      0.00      0.00         3\n",
      "        1704       0.31      0.71      0.43        17\n",
      "        1705       0.00      0.00      0.00         1\n",
      "        1706       0.17      0.55      0.26        11\n",
      "        1707       0.00      0.00      0.00         1\n",
      "        1708       0.00      0.00      0.00         4\n",
      "        1709       0.00      0.00      0.00         8\n",
      "        1710       0.00      0.00      0.00         5\n",
      "        1711       0.14      0.17      0.15         6\n",
      "        1712       0.00      0.00      0.00         2\n",
      "        1713       0.00      0.00      0.00         5\n",
      "        1714       0.00      0.00      0.00         4\n",
      "        1715       0.00      0.00      0.00         3\n",
      "        1716       0.00      0.00      0.00         4\n",
      "        1717       0.00      0.00      0.00         3\n",
      "        1718       0.00      0.00      0.00         5\n",
      "        1719       0.00      0.00      0.00         2\n",
      "        1720       0.00      0.00      0.00         2\n",
      "        1721       0.00      0.00      0.00         3\n",
      "        1722       0.00      0.00      0.00         5\n",
      "        1723       0.23      0.51      0.32        47\n",
      "        1724       0.00      0.00      0.00         2\n",
      "        1725       0.00      0.00      0.00         3\n",
      "        1726       0.00      0.00      0.00         2\n",
      "        1727       0.00      0.00      0.00         2\n",
      "        1728       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21      5407\n",
      "   macro avg       0.02      0.03      0.02      5407\n",
      "weighted avg       0.10      0.21      0.13      5407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DistilBert for Semcor (20210716).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15c2626289b24f4481217dd20dfe49a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "174b7ead6f4d4ef4a3dbc935cd0e1c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19053ccc6bcc4312a3990f08747060c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3cbc4fd56ddc4626bb1d60292f3c1fae",
       "IPY_MODEL_adbd2e21ba3c469d983451160cd1c8cb"
      ],
      "layout": "IPY_MODEL_271712fa9dd040e08df70f3e81d670f6"
     }
    },
    "1ea943039773429da68909ad7c553606": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed2dc8c4000f475088a1d82a56493aa4",
       "IPY_MODEL_81f8f43ed2bf4bbd829e4d4972de526a"
      ],
      "layout": "IPY_MODEL_305723de8e7244049928315a58e0b6e8"
     }
    },
    "22d335ecfac347278a9b51fd5256ff01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "271712fa9dd040e08df70f3e81d670f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c27f976e73547558bfe56a22bf5abb0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fbd22bed9854c48aa0306b97262e22f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c502158f07fd4132b9acf603a036083a",
       "IPY_MODEL_504095b955914b37b6e1faf94ca63dac"
      ],
      "layout": "IPY_MODEL_520a2b4ad663497b9510c601ec756350"
     }
    },
    "30065df54d6a431d934082573413697f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305723de8e7244049928315a58e0b6e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3307cb82e9c3410ca2e1b3d70f34f842": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39beff230cd440c69ee331bef858c567": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cbc4fd56ddc4626bb1d60292f3c1fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdf61e485fd74e61a349fa0f4b85099e",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d18240ea41cd4461ac83bec357cfe163",
      "value": 442
     }
    },
    "4bd6700290bf4208b7923a60e753e1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "504095b955914b37b6e1faf94ca63dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2a38b769ba84d7e922140eba02be013",
      "placeholder": "​",
      "style": "IPY_MODEL_3307cb82e9c3410ca2e1b3d70f34f842",
      "value": " 466k/466k [00:00&lt;00:00, 1.17MB/s]"
     }
    },
    "520a2b4ad663497b9510c601ec756350": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "529fadf0c6824eef8b717d3fc015b0b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c02c35152f44074b66cd4333c53ee3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf5d703cd2d341ee8f8959fe863d9360",
       "IPY_MODEL_b43095072da74bd89019c2ee41404205"
      ],
      "layout": "IPY_MODEL_ead17d90ba6946169c8f5f90ec009625"
     }
    },
    "81f8f43ed2bf4bbd829e4d4972de526a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30065df54d6a431d934082573413697f",
      "placeholder": "​",
      "style": "IPY_MODEL_22d335ecfac347278a9b51fd5256ff01",
      "value": " 28.0/28.0 [00:01&lt;00:00, 14.9B/s]"
     }
    },
    "96454e6a5b50444eb69d6599d0603068": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97f29e2e7ec74e959cd5f8c27f69a6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c27f976e73547558bfe56a22bf5abb0",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd6700290bf4208b7923a60e753e1dd",
      "value": 231508
     }
    },
    "ac0b9fb6ca614ec0b1a72c4c1b625a0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "adbd2e21ba3c469d983451160cd1c8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39beff230cd440c69ee331bef858c567",
      "placeholder": "​",
      "style": "IPY_MODEL_b93b5c0a092d497482f20743313c4da5",
      "value": " 442/442 [00:01&lt;00:00, 391B/s]"
     }
    },
    "b2a38b769ba84d7e922140eba02be013": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b43095072da74bd89019c2ee41404205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7eb4c98104645489338ba7dc9e75b4d",
      "placeholder": "​",
      "style": "IPY_MODEL_cb2c8a118c5340e78ad5cbb723e19cf2",
      "value": " 268M/268M [00:06&lt;00:00, 40.7MB/s]"
     }
    },
    "b59b6733a9ca4efeb627ebf9a4c292da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b93b5c0a092d497482f20743313c4da5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9614946527d4a84b7d2914abdca7638": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97f29e2e7ec74e959cd5f8c27f69a6e0",
       "IPY_MODEL_e14974773ce748c98c9b27fdd14d17ac"
      ],
      "layout": "IPY_MODEL_ba0a51f48f2846168d4941e9d0f1c4e9"
     }
    },
    "ba0a51f48f2846168d4941e9d0f1c4e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c502158f07fd4132b9acf603a036083a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_529fadf0c6824eef8b717d3fc015b0b3",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f343e9f9ad8f470a8efecce10ccb7d2e",
      "value": 466062
     }
    },
    "cb2c8a118c5340e78ad5cbb723e19cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdf61e485fd74e61a349fa0f4b85099e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf5d703cd2d341ee8f8959fe863d9360": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b59b6733a9ca4efeb627ebf9a4c292da",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac0b9fb6ca614ec0b1a72c4c1b625a0a",
      "value": 267967963
     }
    },
    "d18240ea41cd4461ac83bec357cfe163": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e14974773ce748c98c9b27fdd14d17ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96454e6a5b50444eb69d6599d0603068",
      "placeholder": "​",
      "style": "IPY_MODEL_174b7ead6f4d4ef4a3dbc935cd0e1c82",
      "value": " 232k/232k [00:05&lt;00:00, 45.2kB/s]"
     }
    },
    "ead17d90ba6946169c8f5f90ec009625": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed17dea5822b4ccf9fffc8b851b25988": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed2dc8c4000f475088a1d82a56493aa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed17dea5822b4ccf9fffc8b851b25988",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15c2626289b24f4481217dd20dfe49a7",
      "value": 28
     }
    },
    "f343e9f9ad8f470a8efecce10ccb7d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f7eb4c98104645489338ba7dc9e75b4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
